{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f03d6240",
   "metadata": {},
   "source": [
    "# Calculate alignment measures\n",
    "\n",
    "In this notebook, there is code to:\n",
    "* Calculate all alignment metrics for all debates\n",
    "* Look at the descriptive statistics of every metric on the full dataset\n",
    "* Calculate the metrics' correlation with frequency\n",
    "* Calculate the intercorrelation between metrics\n",
    "* Look at results for the running example in the paper\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0355c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import pickle\n",
    "from scipy.spatial.distance import cosine\n",
    "from utils import load_representations, load_similarities, load_cluster_info, load_tfidf\n",
    "from metrics_utils import *\n",
    "from scipy.stats import shapiro, mannwhitneyu\n",
    "import pdb\n",
    "\n",
    "mask_types = ['no-mask','one-mask','multi-mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9def07",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reps = load_representations(\"bert_representations\")\n",
    "all_data = load_similarities(\"bert_representations\")\n",
    "cluster_data = load_cluster_info(\"debates_full_chains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f4da8",
   "metadata": {},
   "source": [
    "# Calculate all alignment metrics + dialign measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1029ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_all_metrics_for_one_debate(debate_id, all_reps, cluster_data):\n",
    "    all_measures_for_debate = []\n",
    "    aggregated_measures = dict()\n",
    "    masks = ['no-mask', 'one-mask', 'multi-mask']\n",
    "    halves = ['first-half', 'second-half']\n",
    "    sides = ['for', 'against']  \n",
    "    all_mentions_overlap = []\n",
    "    all_sides_overlap = []\n",
    "    \n",
    "    for clnum, cl in enumerate(all_reps[debate_id]):          \n",
    "        measures_cluster = dict() \n",
    "        for mask in masks:            \n",
    "            measures_cluster[mask] = dict()\n",
    "            all_reps_per_side = dict()\n",
    "            avg_reps_per_side = dict()\n",
    "            avg_reps_per_side_and_half = dict()\n",
    "            for side in cl[mask]:\n",
    "                avg_reps_per_side_and_half[side] = dict()            \n",
    "                all_reps_per_side[side] = []\n",
    "                for half in halves:    \n",
    "                    all_reps_this_side_and_half = []\n",
    "                    for rep in cl[mask][side][half]: \n",
    "                        all_reps_per_side[side].append(rep['representation'])\n",
    "                        all_reps_this_side_and_half.append(rep['representation'])                    \n",
    "                    avg_reps_per_side_and_half[side][half] = np.average(all_reps_this_side_and_half, axis=0)\n",
    "                    \n",
    "                avg_reps_per_side[side] = np.average(all_reps_per_side[side], axis=0)     \n",
    "            \n",
    "\n",
    "                  \n",
    "                \n",
    "            #####################################\n",
    "            ####### TIME-UNAWARE MEASURES #######\n",
    "            \n",
    "            # SV (Shared vocabulary of a concept) only for clusters of type \"coref\"\n",
    "            \n",
    "            if cluster_data[debate_id]['clusters'][clnum][\"type\"] == \"coref\": \n",
    "                measures_cluster[mask]['SV'] = dict()\n",
    "                mentions = []\n",
    "                sides_by_mention = []\n",
    "                for j, (m_st, m_end) in enumerate(cluster_data[debate_id]['clusters'][clnum]['mentions']):\n",
    "                    mentions.append(\" \".join(cluster_data[debate_id]['document'][m_st:m_end+1]))\n",
    "                    sides_by_mention.append(cluster_data[debate_id]['clusters'][clnum]['speaker_types'][j])\n",
    "                all_mentions_overlap.append(mentions)\n",
    "                all_sides_overlap.append(sides_by_mention)                \n",
    "                overlap, total_freq  = shared_vocabulary_of_concept(mentions, sides_by_mention)                \n",
    "                measures_cluster[mask]['SV']['value'] = overlap\n",
    "                measures_cluster[mask]['SV']['freq'] = total_freq   \n",
    "                \n",
    "                \n",
    "            ### For the other metrics, which will be used for normal words only,\n",
    "            # we want to have at least one instance per word and per side.\n",
    "            # calculate measures for this cluster only if vectors are available\n",
    "            #pdb.set_trace()\n",
    "            vecs_not_available = False\n",
    "            for side in sides:\n",
    "                if np.isnan(avg_reps_per_side[side]).any() or np.isnan(avg_reps_per_side_and_half[side]['first-half']).any() or np.isnan(avg_reps_per_side_and_half[side]['second-half']).any():\n",
    "                    vecs_not_available = True\n",
    "            if vecs_not_available:                \n",
    "                continue         \n",
    "\n",
    "            # Time-unaware self-similarity (SS_{TU})\n",
    "            ss_tu = SS_TU(all_reps_per_side)\n",
    "            measures_cluster[mask]['TUSS_cos'] = ss_tu['cos']\n",
    "            measures_cluster[mask]['TUSS_eucl'] = ss_tu['eucl']\n",
    "\n",
    "\n",
    "            ## Time-unaware other-similarity (OS_{TU})\n",
    "            os_tu = OS_TU(all_reps_per_side)\n",
    "            measures_cluster[mask]['TUOS_cos'] = os_tu['cos']\n",
    "            measures_cluster[mask]['TUOS_eucl'] = os_tu['eucl']                \n",
    "            \n",
    "            \n",
    "            #####################################\n",
    "            ######## TIME AWARE MEASURES ########\n",
    "            \n",
    "            ## Time-aware self-similarity (SS_{TA})\n",
    "            ss_ta = SS_TA(cl, mask)\n",
    "            measures_cluster[mask]['TASS_cos'] = ss_ta['cos']\n",
    "            measures_cluster[mask]['TASS_eucl'] = ss_ta['eucl']\n",
    " \n",
    "            # sApp\n",
    "            sapp = sApp(cl, mask)\n",
    "            measures_cluster[mask]['sApp_cos'] = sapp['cos']\n",
    "            measures_cluster[mask]['sApp_eucl'] = sapp['eucl']\n",
    "            \n",
    "            # asApp  \n",
    "            asapp = asApp(cl, mask)\n",
    "            measures_cluster[mask]['asApp_cos'] = asapp['cos']\n",
    "            measures_cluster[mask]['asApp_eucl'] = asapp['eucl']       \n",
    "\n",
    "            # DS\n",
    "            measures_cluster[mask]['DS_cos'], measures_cluster[mask]['DS_eucl'] = dict(), dict()\n",
    "            measures_cluster[mask]['DS_cos']['for'], measures_cluster[mask]['DS_cos']['against'] = DS(measures_cluster[mask]['asApp_cos']['for'], measures_cluster[mask]['asApp_cos']['against'])\n",
    "            measures_cluster[mask]['DS_eucl']['for'], measures_cluster[mask]['DS_eucl']['against'] = DS(measures_cluster[mask]['asApp_eucl']['for'], measures_cluster[mask]['asApp_eucl']['against'])\n",
    "            \n",
    "        all_measures_for_debate.append(measures_cluster)\n",
    "        \n",
    "    return all_measures_for_debate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41441509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def aggregate_metrics(debate_id, measures_by_word_one_debate, clusters, dialign_measures_this_debate):   \n",
    "    '''Aggregate the values obtained for every metric in one debate according to different vocabulary definitions'''\n",
    "    \n",
    "    tfidfs = load_tfidf(\"tfidf_data/\", debate_id)       \n",
    "    highest_tfidf_words = [w for w, val in sorted(tfidfs.items(), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "    \n",
    "    all_measures_for_debate = []\n",
    "    aggregated_measures = dict()\n",
    "    masks = ['no-mask', 'one-mask', 'multi-mask']\n",
    "    halves = ['first-half', 'second-half']\n",
    "    sides = ['for', 'against']    \n",
    "    vocabulary_options = [\"all\",\"all_words\", \"tfidf200\", \"tfidf200_C\"]\n",
    "   \n",
    "    symmetric_measure_names = [\"TUOS_cos\", \"TUOS_eucl\", 'sApp_cos', 'sApp_eucl', 'SV']\n",
    "    asymmetric_measure_names = [\"TUSS_cos\", \"TUSS_eucl\", 'TASS_cos', 'TASS_eucl', 'DS_cos','DS_eucl','asApp_cos','asApp_eucl']\n",
    "    all_mentions_overlap = []\n",
    "    all_sides_overlap = []\n",
    "    \n",
    "    \n",
    "    all_cluster_names = [cl['cluster_name'] for cl in clusters]    \n",
    "    \n",
    "    # aggregate metrics according to the vocabulary chosen\n",
    "    for vocabulary_option in vocabulary_options: \n",
    "        aggregated_measures[vocabulary_option] = dict()\n",
    "        included_clnums = []            \n",
    "        for clnum, cl in enumerate(clusters):\n",
    "            included = False                                \n",
    "            if cl['type'] == \"word\" and vocabulary_option in [\"all\", \"all_words\"]:\n",
    "                included = True\n",
    "            elif cl['type'] == \"coref\" and vocabulary_option in [\"all\", \"tfidf200_C\"]:\n",
    "                included = True\n",
    "            elif cl['type'] == \"word\" and vocabulary_option in [\"tfidf200\",\"tfidf200_C\"]:\n",
    "                if cl['cluster_name'] in highest_tfidf_words[:200]:      \n",
    "                    included = True\n",
    "            if included:\n",
    "                included_clnums.append(clnum)\n",
    "                \n",
    "\n",
    "        for mask in masks:\n",
    "            aggregated_measures[vocabulary_option][mask] = dict()\n",
    "            for measure in symmetric_measure_names:\n",
    "                if measure == \"SV\": # we take care of this one later, separately\n",
    "                    continue\n",
    "                all_values = []\n",
    "                for clnum in included_clnums:                    \n",
    "                    if measure in measures_by_word_one_debate[clnum][mask]:  \n",
    "                        if np.isnan(measures_by_word_one_debate[clnum][mask][measure]):\n",
    "                            print(\"omitting one nan, cluster\", clnum)                             \n",
    "                            continue\n",
    "                        all_values.append(measures_by_word_one_debate[clnum][mask][measure])\n",
    "                aggregated_measures[vocabulary_option][mask][measure] = np.average(all_values)\n",
    "                \n",
    "            for measure in asymmetric_measure_names:\n",
    "                aggregated_measures[vocabulary_option][mask][measure] = dict()                    \n",
    "                for side in sides:\n",
    "                    all_values = []\n",
    "                    for clnum in included_clnums:\n",
    "                        if measure in measures_by_word_one_debate[clnum][mask]:                            \n",
    "                            if np.isnan(measures_by_word_one_debate[clnum][mask][measure][side]):\n",
    "                                print(\"omitting one nan, cluster\", clnum)\n",
    "                                continue\n",
    "                            all_values.append(measures_by_word_one_debate[clnum][mask][measure][side])\n",
    "                    aggregated_measures[vocabulary_option][mask][measure][side] = np.average(all_values)\n",
    "                    \n",
    "            # Now, SV            \n",
    "            if vocabulary_option in [\"all\", \"all_tfidf200_C\"]:\n",
    "                measure = \"SV\"\n",
    "                sum_freqs_for_overlap = []\n",
    "                for clnum in included_clnums:\n",
    "                    if \"SV\" in measures_by_word_one_debate[clnum][mask]:\n",
    "                        if not np.isnan(measures_by_word_one_debate[clnum][mask]['SV']['value']):\n",
    "                            sum_freqs_for_overlap.append(measures_by_word_one_debate[clnum][mask]['SV']['freq'])\n",
    "                sum_freqs_for_overlap = sum(sum_freqs_for_overlap)\n",
    "\n",
    "                normalized_overlaps = []\n",
    "                for clnum in included_clnums:\n",
    "                    if \"SV\" in measures_by_word_one_debate[clnum][mask]:                    \n",
    "                        ov = measures_by_word_one_debate[clnum][mask]['SV']['value']\n",
    "                        fr = measures_by_word_one_debate[clnum][mask]['SV']['freq']\n",
    "                        if not np.isnan(ov):\n",
    "                            normalized_overlaps.append(ov*fr/sum_freqs_for_overlap)\n",
    "                \n",
    "                aggregated_measures[vocabulary_option][mask][measure] = np.sum(normalized_overlaps)                  \n",
    "\n",
    "                \n",
    "    # now finally, at the debate level, include the Dialign measures\n",
    "    # they are the same regardless of the vocab option or the masking strategy\n",
    "    for vocab_option in aggregated_measures:\n",
    "        for mask in aggregated_measures[vocab_option]:\n",
    "            for measure in dialign_measures_this_debate: \n",
    "                aggregated_measures[vocab_option][mask][measure] = dialign_measures_this_debate[measure] #dialign_measures[debate_id][measure]\n",
    "            \n",
    "    return aggregated_measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "618548ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sdep_measure_name(measure_name):\n",
    "    if \"Initiated Expression\" in measure_name:\n",
    "        return \"Initiated Expression\"\n",
    "    elif \"Expression Repetition\" in measure_name:\n",
    "        return \"Expression Repetition\"\n",
    "    elif \"tokens (%)\" in measure_name:\n",
    "        return \"tokens (%)\"\n",
    "    elif measure_name == \"Voc. Overlap\":\n",
    "        return \"Voc. Overlap\"\n",
    "    elif \"Voc. Overlap\" in measure_name:\n",
    "        return \"SR/Voc. Overlap\"\n",
    "    elif \"/ELS\" in measure_name:\n",
    "        return \"SR/ELS\"\n",
    "    elif \"/EV\" in measure_name:\n",
    "        return \"SR/EV\"\n",
    "    elif \"/ER\" in measure_name:\n",
    "        return \"SR/ER\"\n",
    "    elif \"/ENTR\" in measure_name:\n",
    "        return \"SR/ENTR\"\n",
    "    elif measure_name.endswith(\"/L\"):\n",
    "        return \"SR/L\"\n",
    "    elif \"/LMAX\" in measure_name:\n",
    "        return \"SR/LMAX\"\n",
    "    \n",
    "def load_dialign_info(dialign_dir=\"dialign-output/\"):#\"dialign-output/\"):    \n",
    "    # S1 is against and S2 is for (as we can see in the metrics-speaker-dependent.tsv file)\n",
    "    speaker_dependent_dialign_measure_names = [\"S1/Initiated Expression (IE_S1)\", \"S1/Expression Repetition (ER_S1)\", \"S1/tokens (%)\", \"S2/Initiated Expression (IE_S2)\", \"S2/Expression Repetition (ER_S2)\", \"S2/tokens (%)\", \"Voc. Overlap S1\", \"Voc. Overlap S2\", \"SR/S1/ELS\", \"SR/S1/EV\", \"SR/S1/ER\", \"SR/S1/ENTR\", \"SR/S1/L\", \"SR/S1/LMAX\", \"SR/S2/ELS\", \"SR/S2/EV\", \"SR/S2/ER\", \"SR/S2/ENTR\", \"SR/S2/L\", \"SR/S2/LMAX\"]    \n",
    "    speaker_independent_dialign_measure_names = [\"Num. utterances\", \"Num. tokens\", \"Expression Lexicon Size (ELS)\", \"Expression Variety (EV)\", \"Expression Repetition (ER)\", \"Voc. Overlap\", \"ENTR\", \"L\", \"LMAX\"]\n",
    "    sdep = pd.read_csv(dialign_dir + \"metrics-speaker-dependent.tsv\", sep=\"\\t\")\n",
    "    sindep = pd.read_csv(dialign_dir + \"metrics-speaker-independent.tsv\", sep=\"\\t\")\n",
    "    \n",
    "    dialign_measures = dict()\n",
    "    for i, r in sdep.iterrows():\n",
    "        debate_id = r['ID'].split(\"_\")[0]\n",
    "        dialign_measures[debate_id] = dict()\n",
    "        for k in speaker_dependent_dialign_measure_names:\n",
    "            if \"S1\" in k:\n",
    "                speaker = \"against\"\n",
    "            elif \"S2\" in k:\n",
    "                speaker = \"for\"\n",
    "            simplek = convert_sdep_measure_name(k)\n",
    "            if simplek not in dialign_measures[debate_id]:\n",
    "                dialign_measures[debate_id][simplek] = dict()\n",
    "            dialign_measures[debate_id][simplek][speaker] = r[k]\n",
    "                \n",
    "            \n",
    "    for i, r in sindep.iterrows():\n",
    "        debate_id = r['ID'].split(\"_\")[0]\n",
    "        for k in speaker_independent_dialign_measure_names:\n",
    "            dialign_measures[debate_id][k] = r[k]\n",
    "            \n",
    "    return dialign_measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df89de32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aina/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:495: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/aina/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24565\n",
      "22130\n",
      "8444\n",
      "25403\n",
      "19956\n",
      "11767\n",
      "24036\n",
      "8958\n",
      "4934\n",
      "5180\n",
      "2627\n",
      "13878\n",
      "21641\n",
      "671\n",
      "21166\n",
      "10924\n",
      "19135\n",
      "23135\n",
      "25160\n",
      "4134\n",
      "23602\n",
      "2457\n",
      "5347\n",
      "23945\n",
      "23707\n",
      "3416\n",
      "20577\n",
      "14990\n",
      "7859\n",
      "22879\n",
      "12524\n",
      "25836\n",
      "9973\n",
      "15450\n",
      "18423\n",
      "11136\n",
      "8115\n",
      "2228\n",
      "5703\n",
      "356\n",
      "12277\n",
      "0\n",
      "25635\n",
      "1897\n",
      "6389\n",
      "19373\n",
      "21535\n",
      "20418\n",
      "2807\n",
      "14427\n",
      "4626\n",
      "19607\n",
      "14199\n",
      "9437\n",
      "3735\n",
      "16250\n",
      "21906\n",
      "6660\n",
      "6098\n",
      "24784\n",
      "16500\n",
      "22618\n",
      "20148\n",
      "15726\n",
      "2960\n",
      "5488\n",
      "1177\n",
      "10612\n",
      "14787\n",
      "18181\n",
      "897\n",
      "8797\n",
      "26330\n",
      "9739\n",
      "4395\n",
      "10331\n",
      "17634\n",
      "13265\n",
      "26062\n",
      "3141\n",
      "15975\n",
      "24367\n",
      "9204\n",
      "11368\n",
      "7457\n",
      "13452\n",
      "3948\n",
      "16966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aina/Documents/postdoc/Alignment/DIALOG/for_github/Cleaned_almost_done/metrics_utils.py:298: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DS_a = asapp_a / denominator\n",
      "/home/aina/Documents/postdoc/Alignment/DIALOG/for_github/Cleaned_almost_done/metrics_utils.py:299: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DS_b = asapp_b / denominator\n",
      "/home/aina/Documents/postdoc/Alignment/DIALOG/for_github/Cleaned_almost_done/metrics_utils.py:298: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  DS_a = asapp_a / denominator\n",
      "/home/aina/Documents/postdoc/Alignment/DIALOG/for_github/Cleaned_almost_done/metrics_utils.py:299: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  DS_b = asapp_b / denominator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "omitting one nan, cluster 21\n",
      "17957\n",
      "22390\n",
      "20897\n",
      "5977\n",
      "15258\n",
      "1406\n",
      "23312\n",
      "13608\n",
      "12797\n",
      "16749\n",
      "18864\n",
      "17262\n",
      "7204\n",
      "18672\n",
      "24929\n",
      "11978\n",
      "20803\n",
      "11620\n",
      "1595\n"
     ]
    }
   ],
   "source": [
    "measures_all_debates_by_word = dict()\n",
    "measures_all_debates = dict()\n",
    "\n",
    "# first, calculate dialign measures\n",
    "dialign_measures = load_dialign_info() \n",
    "\n",
    "for debate_id in cluster_data:\n",
    "    print(debate_id)\n",
    "    measures_all_debates_by_word[debate_id] = calculate_all_metrics_for_one_debate(debate_id, all_reps, cluster_data)\n",
    "    measures_all_debates[debate_id] = aggregate_metrics(debate_id, measures_all_debates_by_word[debate_id], cluster_data[debate_id]['clusters'], dialign_measures[debate_id])    \n",
    "    pickle.dump(measures_all_debates_by_word, open(\"measures_all_debates_by_word.pkl\", \"wb\") )\n",
    "    pickle.dump(measures_all_debates, open(\"measures_all_debates.pkl\", \"wb\") )\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6dda1",
   "metadata": {},
   "source": [
    "# Get statistics of each measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f780126",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_all_debates = pickle.load(open(\"measures_all_debates.pkl\", \"rb\"))\n",
    "\n",
    "mask_type = \"no-mask\"\n",
    "             \n",
    "halves = ['first-half', 'second-half']\n",
    "accumulating_stats = dict()\n",
    "almost_all_measures = ['TUOS','sApp','TUSS','TASS','asApp','DS']\n",
    "for measure in almost_all_measures:\n",
    "    accumulating_stats[measure + \"_cos\"] = []\n",
    "    accumulating_stats[measure + \"_eucl\"] = []\n",
    "accumulating_stats[\"SV\"] = []\n",
    "  \n",
    "   \n",
    "for debate_id in measures_all_debates:    \n",
    "    for measure in measures_all_debates[debate_id]['tfidf200'][mask_type]:\n",
    "        if measure not in accumulating_stats:\n",
    "            accumulating_stats[measure] = []\n",
    "        measure_data = measures_all_debates[debate_id]['tfidf200'][mask_type][measure]\n",
    "        if type(measure_data) == type(dict()):\n",
    "            accumulating_stats[measure].append(measure_data['for'])\n",
    "            accumulating_stats[measure].append(measure_data['against'])\n",
    "            if measure + \"-for\" not in accumulating_stats:\n",
    "                accumulating_stats[measure + \"-for\"] = []\n",
    "                accumulating_stats[measure + \"-against\"] = []\n",
    "                \n",
    "            accumulating_stats[measure + \"-for\"].append(measure_data['for'])\n",
    "            accumulating_stats[measure + \"-against\"].append(measure_data['against'])\n",
    "        else:\n",
    "            accumulating_stats[measure].append(measure_data)\n",
    "    measure_data = measures_all_debates[debate_id]['all'][mask_type]['SV']\n",
    "    accumulating_stats['SV'].append(measure_data)\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d04f20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUOS_cos\n",
      "mean 0.6886966178368714\n",
      "min 0.618149715610368\n",
      "max 0.7249803863561425\n",
      "std 0.0189999419941408\n",
      "\n",
      "\n",
      "TUOS_eucl\n",
      "mean 15.519588\n",
      "min 14.334387\n",
      "max 17.519615\n",
      "std 0.5648696\n",
      "\n",
      "\n",
      "sApp_cos\n",
      "mean 0.00795657766178588\n",
      "min -0.05223535190185884\n",
      "max 0.06445713948689255\n",
      "std 0.01769623973653361\n",
      "\n",
      "\n",
      "sApp_eucl\n",
      "mean 0.1669543\n",
      "min -1.5076066\n",
      "max 1.5792781\n",
      "std 0.44769102\n",
      "\n",
      "\n",
      "TUSS_cos\n",
      "mean 0.7084713156007209\n",
      "min 0.6261646579191129\n",
      "max 0.7525489972119453\n",
      "std 0.0204737220659174\n",
      "\n",
      "\n",
      "TUSS_eucl\n",
      "mean 14.922905\n",
      "min 13.291168\n",
      "max 17.365372\n",
      "std 0.63624185\n",
      "\n",
      "\n",
      "TASS_cos\n",
      "mean 0.6968545302155168\n",
      "min 0.6079818733851632\n",
      "max 0.7480730904981894\n",
      "std 0.0223999595513355\n",
      "\n",
      "\n",
      "TASS_eucl\n",
      "mean 15.29295\n",
      "min 13.735255\n",
      "max 17.829676\n",
      "std 0.66253674\n",
      "\n",
      "\n",
      "asApp_cos\n",
      "mean 0.0011667664488276667\n",
      "min -0.04432927819687995\n",
      "max 0.052375381222946264\n",
      "std 0.012434878674773818\n",
      "\n",
      "\n",
      "asApp_eucl\n",
      "mean 0.004654603\n",
      "min -1.1618063\n",
      "max 1.0265634\n",
      "std 0.31641713\n",
      "\n",
      "\n",
      "DS_cos\n",
      "mean 0.021289792539728083\n",
      "min -0.25173833963621783\n",
      "max 0.3383622891513086\n",
      "std 0.1147307076325762\n",
      "\n",
      "\n",
      "DS_eucl\n",
      "mean 0.012886972\n",
      "min -0.22785075\n",
      "max 0.31898448\n",
      "std 0.11621513\n",
      "\n",
      "\n",
      "SV\n",
      "mean 0.8732238605455597\n",
      "min 0.6351731601731603\n",
      "max 1.0\n",
      "std 0.06532924212438622\n",
      "\n",
      "\n",
      "TUSS_cos-for\n",
      "mean 0.709119474065051\n",
      "min 0.6261646579191129\n",
      "max 0.7525489972119453\n",
      "std 0.02111519650012371\n",
      "\n",
      "\n",
      "TUSS_cos-against\n",
      "mean 0.7078231571363903\n",
      "min 0.6534460999115814\n",
      "max 0.7518828964400426\n",
      "std 0.01979027156044766\n",
      "\n",
      "\n",
      "TUSS_eucl-for\n",
      "mean 14.904974\n",
      "min 13.291168\n",
      "max 17.365372\n",
      "std 0.6521725\n",
      "\n",
      "\n",
      "TUSS_eucl-against\n",
      "mean 14.940835\n",
      "min 13.381452\n",
      "max 16.527712\n",
      "std 0.619383\n",
      "\n",
      "\n",
      "TASS_cos-for\n",
      "mean 0.6974638159655662\n",
      "min 0.6079818733851632\n",
      "max 0.7359556040400516\n",
      "std 0.022704478619161285\n",
      "\n",
      "\n",
      "TASS_cos-against\n",
      "mean 0.6962452444654675\n",
      "min 0.6378516856867096\n",
      "max 0.7480730904981894\n",
      "std 0.022074432454415552\n",
      "\n",
      "\n",
      "TASS_eucl-for\n",
      "mean 15.27801\n",
      "min 14.051086\n",
      "max 17.829676\n",
      "std 0.66330487\n",
      "\n",
      "\n",
      "TASS_eucl-against\n",
      "mean 15.307887\n",
      "min 13.735255\n",
      "max 16.64831\n",
      "std 0.6614305\n",
      "\n",
      "\n",
      "DS_cos-for\n",
      "mean 0.02927847465788196\n",
      "min -0.25173833963621783\n",
      "max 0.3383622891513086\n",
      "std 0.120242235836241\n",
      "\n",
      "\n",
      "DS_cos-against\n",
      "mean 0.01330111042157421\n",
      "min -0.23225595033596383\n",
      "max 0.2761298680072966\n",
      "std 0.10835329798799542\n",
      "\n",
      "\n",
      "DS_eucl-for\n",
      "mean 0.02411324\n",
      "min -0.22785075\n",
      "max 0.31898448\n",
      "std 0.120280884\n",
      "\n",
      "\n",
      "DS_eucl-against\n",
      "mean 0.0016607026\n",
      "min -0.20208792\n",
      "max 0.25716358\n",
      "std 0.11087092\n",
      "\n",
      "\n",
      "asApp_cos-for\n",
      "mean 0.0021348169364697267\n",
      "min -0.04432927819687995\n",
      "max 0.052375381222946264\n",
      "std 0.013289479626987032\n",
      "\n",
      "\n",
      "asApp_cos-against\n",
      "mean 0.0001987159611856067\n",
      "min -0.029781689260977403\n",
      "max 0.033611556794440646\n",
      "std 0.011435379445533843\n",
      "\n",
      "\n",
      "asApp_eucl-for\n",
      "mean 0.03421586\n",
      "min -1.1618063\n",
      "max 1.0265634\n",
      "std 0.33386937\n",
      "\n",
      "\n",
      "asApp_eucl-against\n",
      "mean -0.024906648\n",
      "min -0.6352108\n",
      "max 0.74487156\n",
      "std 0.29499674\n",
      "\n",
      "\n",
      "Initiated Expression\n",
      "mean 0.5\n",
      "min 0.3055016181229773\n",
      "max 0.6944983818770226\n",
      "std 0.09962574546630214\n",
      "\n",
      "\n",
      "Initiated Expression-for\n",
      "mean 0.5927344052238891\n",
      "min 0.5153846153846153\n",
      "max 0.6944983818770226\n",
      "std 0.036409054471215875\n",
      "\n",
      "\n",
      "Initiated Expression-against\n",
      "mean 0.40726559477611096\n",
      "min 0.3055016181229773\n",
      "max 0.4846153846153846\n",
      "std 0.036409054471215875\n",
      "\n",
      "\n",
      "Expression Repetition\n",
      "mean 0.5773116906516136\n",
      "min 0.4136949152542373\n",
      "max 0.6786486936262274\n",
      "std 0.05299710155014364\n",
      "\n",
      "\n",
      "Expression Repetition-for\n",
      "mean 0.5314302225367141\n",
      "min 0.4136949152542373\n",
      "max 0.5973217432162575\n",
      "std 0.029633519149193575\n",
      "\n",
      "\n",
      "Expression Repetition-against\n",
      "mean 0.6231931587665133\n",
      "min 0.5654198354803663\n",
      "max 0.6786486936262274\n",
      "std 0.023000475114870286\n",
      "\n",
      "\n",
      "tokens (%)\n",
      "mean 0.5\n",
      "min 0.3831606757978169\n",
      "max 0.6168393242021831\n",
      "std 0.03997436918043438\n",
      "\n",
      "\n",
      "tokens (%)-for\n",
      "mean 0.5050179269970618\n",
      "min 0.3990378904858059\n",
      "max 0.6168393242021831\n",
      "std 0.03965817191986816\n",
      "\n",
      "\n",
      "tokens (%)-against\n",
      "mean 0.49498207300293806\n",
      "min 0.3831606757978169\n",
      "max 0.600962109514194\n",
      "std 0.03965817191986816\n",
      "\n",
      "\n",
      "SR/Voc. Overlap\n",
      "mean 0.4473089136551145\n",
      "min 0.3392760669908157\n",
      "max 0.5509881422924902\n",
      "std 0.037379232791793206\n",
      "\n",
      "\n",
      "SR/Voc. Overlap-for\n",
      "mean 0.4451580896936626\n",
      "min 0.3392760669908157\n",
      "max 0.5509881422924902\n",
      "std 0.037955556720609004\n",
      "\n",
      "\n",
      "SR/Voc. Overlap-against\n",
      "mean 0.4494597376165664\n",
      "min 0.3604513064133016\n",
      "max 0.5193798449612403\n",
      "std 0.036667938513208764\n",
      "\n",
      "\n",
      "SR/ELS\n",
      "mean 1243.4074074074074\n",
      "min 795.0\n",
      "max 1759.0\n",
      "std 193.5679150141058\n",
      "\n",
      "\n",
      "SR/ELS-for\n",
      "mean 1258.8055555555557\n",
      "min 878.0\n",
      "max 1759.0\n",
      "std 197.44133954602415\n",
      "\n",
      "\n",
      "SR/ELS-against\n",
      "mean 1228.0092592592594\n",
      "min 795.0\n",
      "max 1682.0\n",
      "std 188.36078931482305\n",
      "\n",
      "\n",
      "SR/EV\n",
      "mean 0.16307339008943766\n",
      "min 0.1296660117878192\n",
      "max 0.1826821541710665\n",
      "std 0.012087903641992415\n",
      "\n",
      "\n",
      "SR/EV-for\n",
      "mean 0.16339630824519785\n",
      "min 0.1323712366260263\n",
      "max 0.1826821541710665\n",
      "std 0.012081060875515139\n",
      "\n",
      "\n",
      "SR/EV-against\n",
      "mean 0.16275047193367748\n",
      "min 0.1296660117878192\n",
      "max 0.1816258351893095\n",
      "std 0.012086117853456714\n",
      "\n",
      "\n",
      "SR/ER\n",
      "mean 0.8338057419700973\n",
      "min 0.7598177188044498\n",
      "max 0.9009944173063504\n",
      "std 0.023576765187815176\n",
      "\n",
      "\n",
      "SR/ER-for\n",
      "mean 0.8360322160326071\n",
      "min 0.7626931567328918\n",
      "max 0.8901455767077268\n",
      "std 0.02344541389022371\n",
      "\n",
      "\n",
      "SR/ER-against\n",
      "mean 0.8315792679075876\n",
      "min 0.7598177188044498\n",
      "max 0.9009944173063504\n",
      "std 0.0234973595847873\n",
      "\n",
      "\n",
      "SR/ENTR\n",
      "mean 1.8026460888464384\n",
      "min 1.5402795019422209\n",
      "max 2.0433273460265813\n",
      "std 0.09097451055178199\n",
      "\n",
      "\n",
      "SR/ENTR-for\n",
      "mean 1.8034467182724598\n",
      "min 1.5594593715518363\n",
      "max 1.9852383497418065\n",
      "std 0.09073141286638146\n",
      "\n",
      "\n",
      "SR/ENTR-against\n",
      "mean 1.8018454594204174\n",
      "min 1.5402795019422209\n",
      "max 2.0433273460265813\n",
      "std 0.09120993281757853\n",
      "\n",
      "\n",
      "SR/L\n",
      "mean 2.0412003818106217\n",
      "min 1.7320738514383855\n",
      "max 3.247626582278481\n",
      "std 0.27240771779158657\n",
      "\n",
      "\n",
      "SR/L-for\n",
      "mean 2.0456657521623995\n",
      "min 1.7320738514383855\n",
      "max 2.9433363553943788\n",
      "std 0.2552805303077752\n",
      "\n",
      "\n",
      "SR/L-against\n",
      "mean 2.0367350114588434\n",
      "min 1.8006216696269983\n",
      "max 3.247626582278481\n",
      "std 0.288450864456783\n",
      "\n",
      "\n",
      "SR/LMAX\n",
      "mean 72.74074074074075\n",
      "min 5.0\n",
      "max 1066.0\n",
      "std 162.06842235727854\n",
      "\n",
      "\n",
      "SR/LMAX-for\n",
      "mean 92.76851851851852\n",
      "min 5.0\n",
      "max 1066.0\n",
      "std 203.416631684711\n",
      "\n",
      "\n",
      "SR/LMAX-against\n",
      "mean 52.71296296296296\n",
      "min 6.0\n",
      "max 591.0\n",
      "std 101.74378231306815\n",
      "\n",
      "\n",
      "Num. utterances\n",
      "mean 127.39814814814815\n",
      "min 43.0\n",
      "max 297.0\n",
      "std 45.26505066147015\n",
      "\n",
      "\n",
      "Num. tokens\n",
      "mean 15187.981481481482\n",
      "min 10769.0\n",
      "max 22933.0\n",
      "std 2219.022065141082\n",
      "\n",
      "\n",
      "Expression Lexicon Size (ELS)\n",
      "mean 1720.3055555555557\n",
      "min 1182.0\n",
      "max 2260.0\n",
      "std 214.3836323532831\n",
      "\n",
      "\n",
      "Expression Variety (EV)\n",
      "mean 0.11377086230562385\n",
      "min 0.096842352388778\n",
      "max 0.1298012398542851\n",
      "std 0.006832253723563147\n",
      "\n",
      "\n",
      "Expression Repetition (ER)\n",
      "mean 0.5769324662329606\n",
      "min 0.5195021900855177\n",
      "max 0.6076392944749445\n",
      "std 0.0155098924537806\n",
      "\n",
      "\n",
      "Voc. Overlap\n",
      "mean 0.2869943840557109\n",
      "min 0.2293644996347699\n",
      "max 0.3372591006423983\n",
      "std 0.021012766399749395\n",
      "\n",
      "\n",
      "ENTR\n",
      "mean 1.7084744308947295\n",
      "min 1.538973372192165\n",
      "max 1.890118439184327\n",
      "std 0.07531931174852971\n",
      "\n",
      "\n",
      "L\n",
      "mean 1.8586902404228778\n",
      "min 1.720504009163803\n",
      "max 2.042079871348164\n",
      "std 0.06474987754165533\n",
      "\n",
      "\n",
      "LMAX\n",
      "mean 8.092592592592593\n",
      "min 5.0\n",
      "max 17.0\n",
      "std 2.1017498751571053\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for measure in accumulating_stats:\n",
    "    print(measure)\n",
    "    d = accumulating_stats[measure]\n",
    "    print(\"mean\", np.mean(d))\n",
    "    print(\"min\", np.min(d))\n",
    "    print(\"max\", np.max(d))\n",
    "    print(\"std\", np.std(d))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382be429",
   "metadata": {},
   "source": [
    "## Correlation with frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee98f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_all_debates_by_word = pickle.load(open(\"measures_all_debates_by_word.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec8ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_type = \"no-mask\"    \n",
    "    \n",
    "\n",
    "halves = ['first-half', 'second-half']\n",
    "# for each measure: accumulate, for each word, the value of the measure and the number of instances that were used\n",
    "accumulating = dict()\n",
    "for measure in ['TUOS_cos','sApp_cos','TUSS_cos','TASS_cos','asApp_cos','DS_cos']:\n",
    "    accumulating[measure] = {'value':[], 'freq':[]}\n",
    "  \n",
    "   \n",
    "for debate_id in measures_all_debates_by_word:\n",
    "    for clnum, (clmeasures, cl) in enumerate(zip(measures_all_debates_by_word[debate_id], all_data[debate_id])):    \n",
    "        # first, get the number of instances\n",
    "        cl2 = all_reps[debate_id][clnum][mask_type]\n",
    "        all_reps_per_side = dict()        \n",
    "        for side in cl2:        \n",
    "            all_reps_per_side[side] = []\n",
    "            for half in halves:    \n",
    "                all_reps_this_side_and_half = []\n",
    "                for rep in cl2[side][half]: \n",
    "                    all_reps_per_side[side].append(rep['representation'])\n",
    "                    \n",
    "        \n",
    "        \n",
    "        for sym_m in [\"TUOS_cos\",\"sApp_cos\"]:\n",
    "            if sym_m in clmeasures[mask_type]:\n",
    "                accumulating[sym_m]['value'].append(clmeasures[mask_type][sym_m])\n",
    "                accumulating[sym_m]['freq'].append(len(all_reps_per_side['for']) + len(all_reps_per_side['against']))\n",
    "        \n",
    "        for asym_m in [\"TUSS_cos\", \"TASS_cos\", \"asApp_cos\", \"DS_cos\"]:\n",
    "            if asym_m in clmeasures[mask_type]:\n",
    "                if not np.isnan(clmeasures[mask_type][asym_m]['for']):\n",
    "                    accumulating[asym_m]['value'].append(clmeasures[mask_type][asym_m]['for'])\n",
    "                    accumulating[asym_m]['freq'].append(len(all_reps_per_side['for']))\n",
    "                if not np.isnan(clmeasures[mask_type][asym_m]['against']):\n",
    "                    accumulating[asym_m]['value'].append(clmeasures[mask_type][asym_m]['against'])\n",
    "                    accumulating[asym_m]['freq'].append(len(all_reps_per_side['against']))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c72832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUOS_cos rho: 0.006 p-value: 0.577\n",
      "sApp_cos rho: 0.006 p-value: 0.572\n",
      "TUSS_cos rho: -0.034 p-value: 0.0\n",
      "TASS_cos rho: -0.013 p-value: 0.076\n",
      "asApp_cos rho: 0.015 p-value: 0.047\n",
      "DS_cos rho: 0.015 p-value: 0.046\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "for measure in accumulating:\n",
    "    rho, p = spearmanr(accumulating[measure]['freq'], accumulating[measure]['value'])\n",
    "    print(measure, \"rho:\",  rho.round(3), \"p-value:\", p.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc302e4",
   "metadata": {},
   "source": [
    "# Intercorrelations between measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78fff478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.9708045721054077, pvalue=0.01771170273423195)\n",
      "ShapiroResult(statistic=0.9834761619567871, pvalue=0.012576954439282417)\n",
      "ShapiroResult(statistic=0.9760144948959351, pvalue=0.0009683974785730243)\n"
     ]
    }
   ],
   "source": [
    "# Check how different TU other-similarity is from TA self-similarity and TU self-similarity\n",
    "\n",
    "# check for normality\n",
    "print(shapiro(accumulating_stats['TUOS_cos']))\n",
    "print(shapiro(accumulating_stats['TUSS_cos']))\n",
    "print(shapiro(accumulating_stats['TASS_cos']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c890b205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time-unaware other-similarity vs time-unaware self-similarity:\n",
      "MannwhitneyuResult(statistic=5419.0, pvalue=3.962297598859403e-15)\n",
      "time-unaware other-similarity vs time-aware self-similarity:\n",
      "MannwhitneyuResult(statistic=8894.0, pvalue=0.0004934849880349604)\n",
      "time-unaware self-similarity vs time-aware self-similarity:\n",
      "MannwhitneyuResult(statistic=30328.0, pvalue=6.867307628487382e-08)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# not normal -> mann whitney\n",
    "print(\"time-unaware other-similarity vs time-unaware self-similarity:\")\n",
    "print(mannwhitneyu(accumulating_stats['TUOS_cos'], accumulating_stats['TUSS_cos']))\n",
    "\n",
    "print(\"time-unaware other-similarity vs time-aware self-similarity:\")\n",
    "print(mannwhitneyu(accumulating_stats['TUOS_cos'], accumulating_stats['TASS_cos']))\n",
    "\n",
    "print(\"time-unaware self-similarity vs time-aware self-similarity:\")\n",
    "print(mannwhitneyu(accumulating_stats['TUSS_cos'], accumulating_stats['TASS_cos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90eafc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUOS_cos sApp_cos rho: -0.07 p-value: 0.474\n",
      "TUOS_cos Num. utterances rho: 0.033 p-value: 0.738\n",
      "TUOS_cos Num. tokens rho: -0.166 p-value: 0.086\n",
      "TUOS_cos Expression Lexicon Size (ELS) rho: -0.161 p-value: 0.095\n",
      "TUOS_cos Voc. Overlap rho: 0.226 p-value: 0.019\n",
      "TUOS_cos Expression Variety (EV) rho: 0.179 p-value: 0.064\n",
      "TUOS_cos Expression Repetition (ER) rho: 0.04 p-value: 0.68\n",
      "TUOS_cos ENTR rho: 0.011 p-value: 0.911\n",
      "TUOS_cos L rho: -0.013 p-value: 0.893\n",
      "TUOS_cos LMAX rho: 0.056 p-value: 0.566\n",
      "sApp_cos Num. utterances rho: 0.125 p-value: 0.198\n",
      "sApp_cos Num. tokens rho: 0.031 p-value: 0.751\n",
      "sApp_cos Expression Lexicon Size (ELS) rho: -0.024 p-value: 0.803\n",
      "sApp_cos Voc. Overlap rho: -0.121 p-value: 0.212\n",
      "sApp_cos Expression Variety (EV) rho: -0.101 p-value: 0.299\n",
      "sApp_cos Expression Repetition (ER) rho: -0.161 p-value: 0.095\n",
      "sApp_cos ENTR rho: -0.002 p-value: 0.987\n",
      "sApp_cos L rho: -0.012 p-value: 0.906\n",
      "sApp_cos LMAX rho: -0.002 p-value: 0.987\n",
      "Num. utterances Num. tokens rho: 0.419 p-value: 0.0\n",
      "Num. utterances Expression Lexicon Size (ELS) rho: 0.465 p-value: 0.0\n",
      "Num. utterances Voc. Overlap rho: 0.049 p-value: 0.614\n",
      "Num. utterances Expression Variety (EV) rho: -0.03 p-value: 0.76\n",
      "Num. utterances Expression Repetition (ER) rho: 0.182 p-value: 0.06\n",
      "Num. utterances ENTR rho: 0.187 p-value: 0.053\n",
      "Num. utterances L rho: 0.216 p-value: 0.025\n",
      "Num. utterances LMAX rho: 0.168 p-value: 0.083\n",
      "Num. tokens Expression Lexicon Size (ELS) rho: 0.887 p-value: 0.0\n",
      "Num. tokens Voc. Overlap rho: -0.146 p-value: 0.132\n",
      "Num. tokens Expression Variety (EV) rho: -0.428 p-value: 0.0\n",
      "Num. tokens Expression Repetition (ER) rho: 0.443 p-value: 0.0\n",
      "Num. tokens ENTR rho: 0.616 p-value: 0.0\n",
      "Num. tokens L rho: 0.685 p-value: 0.0\n",
      "Num. tokens LMAX rho: 0.301 p-value: 0.002\n",
      "Expression Lexicon Size (ELS) Voc. Overlap rho: 0.149 p-value: 0.125\n",
      "Expression Lexicon Size (ELS) Expression Variety (EV) rho: -0.035 p-value: 0.72\n",
      "Expression Lexicon Size (ELS) Expression Repetition (ER) rho: 0.629 p-value: 0.0\n",
      "Expression Lexicon Size (ELS) ENTR rho: 0.58 p-value: 0.0\n",
      "Expression Lexicon Size (ELS) L rho: 0.695 p-value: 0.0\n",
      "Expression Lexicon Size (ELS) LMAX rho: 0.296 p-value: 0.002\n",
      "Voc. Overlap Expression Variety (EV) rho: 0.725 p-value: 0.0\n",
      "Voc. Overlap Expression Repetition (ER) rho: 0.411 p-value: 0.0\n",
      "Voc. Overlap ENTR rho: -0.117 p-value: 0.229\n",
      "Voc. Overlap L rho: -0.037 p-value: 0.7\n",
      "Voc. Overlap LMAX rho: -0.17 p-value: 0.079\n",
      "Expression Variety (EV) Expression Repetition (ER) rho: 0.263 p-value: 0.006\n",
      "Expression Variety (EV) ENTR rho: -0.221 p-value: 0.022\n",
      "Expression Variety (EV) L rho: -0.157 p-value: 0.105\n",
      "Expression Variety (EV) LMAX rho: -0.06 p-value: 0.538\n",
      "Expression Repetition (ER) ENTR rho: 0.404 p-value: 0.0\n",
      "Expression Repetition (ER) L rho: 0.522 p-value: 0.0\n",
      "Expression Repetition (ER) LMAX rho: 0.103 p-value: 0.288\n",
      "ENTR L rho: 0.95 p-value: 0.0\n",
      "ENTR LMAX rho: 0.443 p-value: 0.0\n",
      "L LMAX rho: 0.436 p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "##### symmetric measures\n",
    "\n",
    "sms = ['TUOS_cos','sApp_cos']\n",
    "\n",
    "# if we want to include Dialign symmetric measures:\n",
    "sms += [\"Num. utterances\", \"Num. tokens\", \"Expression Lexicon Size (ELS)\", \"Voc. Overlap\", \"Expression Variety (EV)\", \"Expression Repetition (ER)\", \"ENTR\", \"L\", \"LMAX\"]\n",
    "\n",
    "for j, sm in enumerate(sms):\n",
    "    for othersm in sms[j+1:]:                \n",
    "        rho, p = spearmanr(accumulating_stats[sm], accumulating_stats[othersm])    \n",
    "        print(sm, othersm, \"rho:\",  rho.round(3), \"p-value:\", p.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e286f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TUSS_cos TASS_cos rho: 0.934 p-value: 0.0\n",
      "TUSS_cos asApp_cos rho: -0.158 p-value: 0.02\n",
      "TUSS_cos DS_cos rho: -0.185 p-value: 0.006\n",
      "TUSS_cos Initiated Expression rho: 0.063 p-value: 0.358\n",
      "TUSS_cos Expression Repetition rho: -0.05 p-value: 0.465\n",
      "TUSS_cos tokens (%) rho: -0.014 p-value: 0.837\n",
      "TUSS_cos SR/ELS rho: -0.057 p-value: 0.402\n",
      "TUSS_cos SR/EV rho: 0.174 p-value: 0.01\n",
      "TUSS_cos SR/ER rho: 0.263 p-value: 0.0\n",
      "TUSS_cos SR/ENTR rho: 0.196 p-value: 0.004\n",
      "TUSS_cos SR/L rho: 0.166 p-value: 0.015\n",
      "TUSS_cos SR/LMAX rho: 0.072 p-value: 0.295\n",
      "TASS_cos asApp_cos rho: -0.091 p-value: 0.182\n",
      "TASS_cos DS_cos rho: -0.134 p-value: 0.048\n",
      "TASS_cos Initiated Expression rho: 0.032 p-value: 0.644\n",
      "TASS_cos Expression Repetition rho: -0.029 p-value: 0.667\n",
      "TASS_cos tokens (%) rho: -0.043 p-value: 0.534\n",
      "TASS_cos SR/ELS rho: -0.074 p-value: 0.277\n",
      "TASS_cos SR/EV rho: 0.306 p-value: 0.0\n",
      "TASS_cos SR/ER rho: 0.198 p-value: 0.003\n",
      "TASS_cos SR/ENTR rho: 0.123 p-value: 0.071\n",
      "TASS_cos SR/L rho: 0.04 p-value: 0.558\n",
      "TASS_cos SR/LMAX rho: -0.057 p-value: 0.407\n",
      "asApp_cos DS_cos rho: 0.77 p-value: 0.0\n",
      "asApp_cos Initiated Expression rho: -0.022 p-value: 0.75\n",
      "asApp_cos Expression Repetition rho: -0.037 p-value: 0.584\n",
      "asApp_cos tokens (%) rho: 0.029 p-value: 0.672\n",
      "asApp_cos SR/ELS rho: 0.04 p-value: 0.559\n",
      "asApp_cos SR/EV rho: -0.084 p-value: 0.219\n",
      "asApp_cos SR/ER rho: -0.075 p-value: 0.274\n",
      "asApp_cos SR/ENTR rho: -0.029 p-value: 0.669\n",
      "asApp_cos SR/L rho: -0.01 p-value: 0.889\n",
      "asApp_cos SR/LMAX rho: -0.074 p-value: 0.279\n",
      "DS_cos Initiated Expression rho: -0.008 p-value: 0.91\n",
      "DS_cos Expression Repetition rho: -0.069 p-value: 0.314\n",
      "DS_cos tokens (%) rho: 0.062 p-value: 0.368\n",
      "DS_cos SR/ELS rho: -0.023 p-value: 0.739\n",
      "DS_cos SR/EV rho: -0.105 p-value: 0.122\n",
      "DS_cos SR/ER rho: -0.144 p-value: 0.035\n",
      "DS_cos SR/ENTR rho: -0.076 p-value: 0.266\n",
      "DS_cos SR/L rho: -0.05 p-value: 0.467\n",
      "DS_cos SR/LMAX rho: -0.071 p-value: 0.296\n",
      "Initiated Expression Expression Repetition rho: -0.91 p-value: 0.0\n",
      "Initiated Expression tokens (%) rho: 0.136 p-value: 0.045\n",
      "Initiated Expression SR/ELS rho: 0.086 p-value: 0.209\n",
      "Initiated Expression SR/EV rho: 0.052 p-value: 0.447\n",
      "Initiated Expression SR/ER rho: 0.157 p-value: 0.021\n",
      "Initiated Expression SR/ENTR rho: 0.077 p-value: 0.257\n",
      "Initiated Expression SR/L rho: 0.123 p-value: 0.071\n",
      "Initiated Expression SR/LMAX rho: 0.079 p-value: 0.251\n",
      "Expression Repetition tokens (%) rho: -0.062 p-value: 0.363\n",
      "Expression Repetition SR/ELS rho: 0.128 p-value: 0.06\n",
      "Expression Repetition SR/EV rho: 0.081 p-value: 0.236\n",
      "Expression Repetition SR/ER rho: 0.074 p-value: 0.279\n",
      "Expression Repetition SR/ENTR rho: 0.108 p-value: 0.115\n",
      "Expression Repetition SR/L rho: 0.027 p-value: 0.698\n",
      "Expression Repetition SR/LMAX rho: -0.101 p-value: 0.14\n",
      "tokens (%) SR/ELS rho: 0.502 p-value: 0.0\n",
      "tokens (%) SR/EV rho: 0.114 p-value: 0.095\n",
      "tokens (%) SR/ER rho: 0.367 p-value: 0.0\n",
      "tokens (%) SR/ENTR rho: 0.196 p-value: 0.004\n",
      "tokens (%) SR/L rho: 0.234 p-value: 0.001\n",
      "tokens (%) SR/LMAX rho: 0.118 p-value: 0.083\n",
      "SR/ELS SR/EV rho: 0.188 p-value: 0.006\n",
      "SR/ELS SR/ER rho: 0.695 p-value: 0.0\n",
      "SR/ELS SR/ENTR rho: 0.532 p-value: 0.0\n",
      "SR/ELS SR/L rho: 0.516 p-value: 0.0\n",
      "SR/ELS SR/LMAX rho: 0.157 p-value: 0.021\n",
      "SR/EV SR/ER rho: 0.199 p-value: 0.003\n",
      "SR/EV SR/ENTR rho: -0.063 p-value: 0.357\n",
      "SR/EV SR/L rho: -0.241 p-value: 0.0\n",
      "SR/EV SR/LMAX rho: -0.53 p-value: 0.0\n",
      "SR/ER SR/ENTR rho: 0.646 p-value: 0.0\n",
      "SR/ER SR/L rho: 0.722 p-value: 0.0\n",
      "SR/ER SR/LMAX rho: 0.266 p-value: 0.0\n",
      "SR/ENTR SR/L rho: 0.847 p-value: 0.0\n",
      "SR/ENTR SR/LMAX rho: 0.379 p-value: 0.0\n",
      "SR/L SR/LMAX rho: 0.601 p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Asymmetric measures\n",
    "\n",
    "asms = ['TUSS_cos','TASS_cos','asApp_cos','DS_cos']\n",
    "\n",
    "# if we want to include Dialign asymmetric measures:\n",
    "asms += [\"Initiated Expression\", \"Expression Repetition\", \"tokens (%)\", \"SR/ELS\", \"SR/EV\", \"SR/ER\", \"SR/ENTR\", \"SR/L\", \"SR/LMAX\"]\n",
    "for j, asm in enumerate(asms):\n",
    "    for otherasm in asms[j+1:]:                \n",
    "        rho, p = spearmanr(accumulating_stats[asm], accumulating_stats[otherasm])    \n",
    "        print(asm, otherasm, \"rho:\",  rho.round(3), \"p-value:\", p.round(3))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db749e",
   "metadata": {},
   "source": [
    "# Looking at results for a running example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "631e62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_debate = '8444'\n",
    "mask_type = \"no-mask\"\n",
    "tfidf = load_tfidf(\"tfidf_data/\", chosen_debate)    \n",
    "highest_tfidf_words = [w for w, val in sorted(tfidf.items(), key=lambda x: x[1], reverse=True)] \n",
    "measures_all_debates_by_word = pickle.load(open(\"measures_all_debates_by_word.pkl\", \"rb\"))\n",
    "sides = ['for','against']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c34b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-unaware other-similarity\n",
      "[('life_NOUN', 0.4962246185541153), ('attack_NOUN', 0.5296459520856539), ('grow_VERB', 0.5799237829115655), ('die_VERB', 0.6015136301517486), ('study_NOUN', 0.653983896665084), ('cow_NOUN', 0.6578269640604655), ('health_NOUN', 0.6587509968451091), ('kill_VERB', 0.677951312901681), ('fat_NOUN', 0.680682917435964), ('heart_NOUN', 0.7008274895804268), ('eat_VERB', 0.7012726261600879), ('farm_NOUN', 0.7052367757473673), ('anything_NOUN', 0.7076885513961315), ('plant_NOUN', 0.7094313116300673), ('diet_NOUN', 0.712994020515018), ('soil_NOUN', 0.7235075639826911), ('food_NOUN', 0.7275728983756823), ('corn_NOUN', 0.7345363242285592), ('vegetable_NOUN', 0.7383664300044378), ('animal_NOUN', 0.74377097497518), ('vegan_NOUN', 0.7611156387461556), ('vegetarian_NOUN', 0.7614651247859001), ('human_NOUN', 0.7784551461537679), ('cancer_NOUN', 0.7810741012942963), ('farming_NOUN', 0.7826763954427507), ('meat_NOUN', 0.7911718515714923), ('factory_NOUN', 0.7913300457100073), ('face_NOUN', 0.8062775318139519)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Time-unaware other-similarity\")\n",
    "\n",
    "sims = []\n",
    "for clnum, (clmeasures, cl) in enumerate(zip(measures_all_debates_by_word[chosen_debate], all_data[chosen_debate])):    \n",
    "    if cl['type'] == \"word\" and 'TUOS_cos' in clmeasures[mask_type]:        \n",
    "        sims.append([cl['cluster_name'], clmeasures[mask_type]['TUOS_cos']])\n",
    "\n",
    "sims = sorted(sims, key=lambda k: k[1])\n",
    "\n",
    "print([(w,s) for w,s  in sims if w in highest_tfidf_words[:200]])      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fe90547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sApp\n",
      "[('study_NOUN', -0.10353074556764941), ('fat_NOUN', -0.0723167359828949), ('vegetarian_NOUN', -0.066703466574351), ('health_NOUN', -0.06241555412610378), ('soil_NOUN', -0.025006538850289806), ('plant_NOUN', -0.024028644202247595), ('food_NOUN', -0.012455905228853204), ('farming_NOUN', -0.0051993876695632935), ('farm_NOUN', -0.0029923066496849726), ('vegetable_NOUN', 0.00337044894695282), ('diet_NOUN', 0.0047436047823001815), ('factory_NOUN', 0.017411991528102355), ('kill_VERB', 0.02145541674560969), ('human_NOUN', 0.02726541956265771), ('vegan_NOUN', 0.027536392211914062), ('animal_NOUN', 0.027579561992505996), ('cancer_NOUN', 0.03358164954753151), ('heart_NOUN', 0.042348772287368774), ('eat_VERB', 0.05339107786278863), ('meat_NOUN', 0.05380304044459283), ('corn_NOUN', 0.07488928834597275), ('die_VERB', 0.09598531041826519), ('life_NOUN', 0.09731096277634305), ('face_NOUN', 0.19236883922265124), ('anything_NOUN', 0.2578541029776845), ('attack_NOUN', 0.2705521285533905), ('grow_VERB', 0.3069024001558621), ('cow_NOUN', 0.5710987821221352)]\n"
     ]
    }
   ],
   "source": [
    "print(\"sApp\")\n",
    "\n",
    "sims = []\n",
    "for clnum, (clmeasures, cl) in enumerate(zip(measures_all_debates_by_word[chosen_debate], all_data[chosen_debate])):    \n",
    "    if cl['type'] == \"word\" and 'sApp_cos' in clmeasures[mask_type]:        \n",
    "        sims.append([cl['cluster_name'], clmeasures[mask_type]['sApp_cos']])\n",
    "\n",
    "sims = sorted(sims, key=lambda k: k[1])\n",
    "\n",
    "print([(w,s) for w,s  in sims if w in highest_tfidf_words[:200]])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d2e5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-unaware self-similarity\n",
      "for\n",
      "[('life_NOUN', 0.472505646944046), ('grow_VERB', 0.5247118292432843), ('cow_NOUN', 0.5716675619284312), ('die_VERB', 0.608405898917805), ('study_NOUN', 0.6701231104987008), ('kill_VERB', 0.6769836443906639), ('health_NOUN', 0.6777468979358673), ('fat_NOUN', 0.7122666835784912), ('plant_NOUN', 0.7189967825299217), ('farm_NOUN', 0.721231592237634), ('eat_VERB', 0.7213188296431428), ('diet_NOUN', 0.722347134635562), ('corn_NOUN', 0.7306215763092041), ('food_NOUN', 0.7326622009277344), ('vegetable_NOUN', 0.7354978720347086), ('heart_NOUN', 0.772115979875837), ('soil_NOUN', 0.7749007741610209), ('face_NOUN', 0.7776305585661355), ('animal_NOUN', 0.7811320628426067), ('human_NOUN', 0.7933973471323649), ('vegetarian_NOUN', 0.7934302091598511), ('meat_NOUN', 0.7943228853127313), ('cancer_NOUN', 0.7986196738929145), ('attack_NOUN', 0.8130845824877421), ('factory_NOUN', 0.8202720302523989), ('vegan_NOUN', 0.8390943924585978), ('farming_NOUN', 0.8852119843165079), ('anything_NOUN', 0.8905094883271626)]\n",
      "against\n",
      "[('attack_NOUN', 0.4779975811640422), ('life_NOUN', 0.5244215627511343), ('anything_NOUN', 0.6182835380236308), ('die_VERB', 0.6270894557237625), ('study_NOUN', 0.6595439070921678), ('health_NOUN', 0.6638634889335423), ('grow_VERB', 0.6790465099944009), ('fat_NOUN', 0.6838486591974894), ('eat_VERB', 0.6890180672447525), ('plant_NOUN', 0.7103108141448472), ('heart_NOUN', 0.7130325257778167), ('soil_NOUN', 0.7182935718651656), ('animal_NOUN', 0.7227006600453303), ('food_NOUN', 0.7317621091695933), ('vegan_NOUN', 0.7412550846735636), ('vegetable_NOUN', 0.7412950375250408), ('diet_NOUN', 0.7415769630008273), ('farm_NOUN', 0.742112766371833), ('kill_VERB', 0.7443149407704671), ('corn_NOUN', 0.7518490496135893), ('vegetarian_NOUN', 0.7564720312754313), ('factory_NOUN', 0.7602998316287994), ('cow_NOUN', 0.7628163516521453), ('cancer_NOUN', 0.7776535180481997), ('human_NOUN', 0.7782474219799042), ('farming_NOUN', 0.7804958621660868), ('meat_NOUN', 0.7910265050498135), ('face_NOUN', 0.838598844077852)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Time-unaware self-similarity\")\n",
    "\n",
    "for side in sides:\n",
    "    print(side)\n",
    "    sims = []\n",
    "    for clnum, (clmeasures, cl) in enumerate(zip(measures_all_debates_by_word[chosen_debate], all_data[chosen_debate])):    \n",
    "        if cl['type'] == \"word\" and 'TUSS_cos' in clmeasures[mask_type]:        \n",
    "            sims.append([cl['cluster_name'], clmeasures[mask_type]['TUSS_cos'][side]])\n",
    "    \n",
    "    sims = sorted(sims, key=lambda k: k[1])   \n",
    "    print([(w,s) for w,s  in sims if w in highest_tfidf_words[:200]])  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "731e23f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-aware self-similarity\n",
      "for\n",
      "[('grow_VERB', 0.36258082538843156), ('cow_NOUN', 0.36976204812526703), ('life_NOUN', 0.4519957850376765), ('die_VERB', 0.5695393204689025), ('kill_VERB', 0.6465546071529389), ('study_NOUN', 0.6603089548074282), ('health_NOUN', 0.6638030707836151), ('face_NOUN', 0.6641981481359556), ('corn_NOUN', 0.6731112798055013), ('vegetable_NOUN', 0.6748226881027222), ('fat_NOUN', 0.6761690179506937), ('farm_NOUN', 0.714560283968846), ('diet_NOUN', 0.7153155318012944), ('eat_VERB', 0.7159358366524301), ('plant_NOUN', 0.7174114540771201), ('food_NOUN', 0.7190590369701385), ('cancer_NOUN', 0.7698458078361693), ('animal_NOUN', 0.7809303918159131), ('vegetarian_NOUN', 0.7894826730092367), ('meat_NOUN', 0.7942012401060624), ('attack_NOUN', 0.7955980896949768), ('human_NOUN', 0.8038281202316284), ('heart_NOUN', 0.8065096040566763), ('soil_NOUN', 0.8124979734420776), ('factory_NOUN', 0.8205675278391157), ('vegan_NOUN', 0.8470671847462654), ('farming_NOUN', 0.8770907521247864), ('anything_NOUN', 0.9124725375856672)]\n",
      "\n",
      "\n",
      "against\n",
      "[('life_NOUN', 0.4958938155323267), ('attack_NOUN', 0.5290241539478302), ('study_NOUN', 0.5581961025420884), ('health_NOUN', 0.6209556228584714), ('die_VERB', 0.6229866097370783), ('anything_NOUN', 0.6333167850971222), ('grow_VERB', 0.6502818365891775), ('eat_VERB', 0.6713661482700934), ('vegan_NOUN', 0.7091048806905746), ('plant_NOUN', 0.7096031393323626), ('animal_NOUN', 0.7120543457662968), ('soil_NOUN', 0.7151616666052076), ('kill_VERB', 0.7163688474231296), ('food_NOUN', 0.7180067364126443), ('farm_NOUN', 0.7240363931655884), ('heart_NOUN', 0.724511444568634), ('fat_NOUN', 0.7255185544490814), ('corn_NOUN', 0.7365433692932128), ('vegetable_NOUN', 0.7404779295126597), ('diet_NOUN', 0.7440288974688604), ('factory_NOUN', 0.7605557590723038), ('vegetarian_NOUN', 0.7789713501930237), ('farming_NOUN', 0.7829688787460327), ('human_NOUN', 0.7835492889086405), ('meat_NOUN', 0.789396988210224), ('cow_NOUN', 0.7958490699529648), ('cancer_NOUN', 0.8085758000612259), ('face_NOUN', 0.8550869598984718)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Time-aware self-similarity')\n",
    "\n",
    "for side in sides:\n",
    "    print(side)\n",
    "    sims = []\n",
    "    for clnum, (clmeasures, cl) in enumerate(zip(measures_all_debates_by_word[chosen_debate], all_data[chosen_debate])):    \n",
    "        if cl['type'] == \"word\" and 'TASS_cos' in clmeasures[mask_type]:        \n",
    "            sims.append([cl['cluster_name'], clmeasures[mask_type]['TASS_cos'][side]])\n",
    "    \n",
    "    sims = sorted(sims, key=lambda k: k[1])   \n",
    "    \n",
    "    print([(w,s) for w,s  in sims if w in highest_tfidf_words[:200]])   \n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fdc9dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asApp\n",
      "for\n",
      "[('vegetarian_NOUN', -0.07820104757944746), ('fat_NOUN', -0.07737517356872559), ('study_NOUN', -0.047620566750344984), ('vegan_NOUN', -0.02243252843618393), ('farming_NOUN', -0.0216200053691864), ('farm_NOUN', -0.012796506782372874), ('plant_NOUN', -0.01197079107874921), ('health_NOUN', -0.004005060151771267), ('eat_VERB', -0.00044260350669311777), ('animal_NOUN', 3.9223688443335014e-05), ('vegetable_NOUN', 0.0009212444225946692), ('cancer_NOUN', 0.003389846569015864), ('soil_NOUN', 0.006523732785825409), ('heart_NOUN', 0.007257193326950073), ('diet_NOUN', 0.008224873970716473), ('factory_NOUN', 0.010246568066733186), ('meat_NOUN', 0.014662886919913354), ('anything_NOUN', 0.015271116580281907), ('corn_NOUN', 0.015841225783030155), ('food_NOUN', 0.017951076850295067), ('kill_VERB', 0.01878183053599458), ('die_VERB', 0.02298169944967543), ('life_NOUN', 0.03330994832019013), ('attack_NOUN', 0.06580100953578949), ('human_NOUN', 0.08351597189903259), ('face_NOUN', 0.2239031046628952), ('grow_VERB', 0.2905729780594508), ('cow_NOUN', 0.42692849785089493)]\n",
      "\n",
      "\n",
      "against\n",
      "[('study_NOUN', -0.14022062864518703), ('health_NOUN', -0.13116881151994075), ('food_NOUN', -0.027324755340814577), ('plant_NOUN', -0.02640312910079956), ('soil_NOUN', -0.020507206740202677), ('human_NOUN', -0.019079148769378662), ('diet_NOUN', -0.009042077339612486), ('grow_VERB', -0.0029001956184704913), ('kill_VERB', -0.0009484986464183276), ('life_NOUN', 0.0006422599156697961), ('cow_NOUN', 0.00186128169298172), ('vegan_NOUN', 0.0023564770817756653), ('die_VERB', 0.003822416067123413), ('farming_NOUN', 0.00869038701057434), ('fat_NOUN', 0.010789304971694946), ('factory_NOUN', 0.011122959852218561), ('farm_NOUN', 0.012608961760997683), ('face_NOUN', 0.019020548090338707), ('corn_NOUN', 0.025532120466232322), ('animal_NOUN', 0.028740361128226533), ('vegetarian_NOUN', 0.030946723620096872), ('cancer_NOUN', 0.033305304674875136), ('heart_NOUN', 0.037249788641929626), ('meat_NOUN', 0.037845470224108), ('eat_VERB', 0.04918770363479297), ('vegetable_NOUN', 0.09249520301818848), ('attack_NOUN', 0.14091939727465308), ('anything_NOUN', 0.24229539185762405)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('asApp')\n",
    "side_idcs = {'for':0,'against':1}\n",
    "for side in sides:    \n",
    "    print(side)\n",
    "    sims = []\n",
    "    for clnum, (clmeasures, cl) in enumerate(zip(measures_all_debates_by_word[chosen_debate], all_data[chosen_debate])):    \n",
    "        if cl['type'] == \"word\" and 'asApp_cos' in clmeasures[mask_type]:        \n",
    "            sims.append([cl['cluster_name'], clmeasures[mask_type]['asApp_cos'][side]])\n",
    "    \n",
    "    sims = sorted(sims, key=lambda k: k[1])    \n",
    "    print([(w,s) for w,s  in sims if w in highest_tfidf_words[:200]])   \n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c55d2bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS\n",
      "for\n",
      "[('vegan_NOUN', -0.904938619660704), ('fat_NOUN', -0.8776229934060302), ('vegetarian_NOUN', -0.7164694864586839), ('farming_NOUN', -0.713286885181427), ('farm_NOUN', -0.5036910364604185), ('plant_NOUN', -0.31195121641830575), ('study_NOUN', -0.25351503247235874), ('health_NOUN', -0.02962895197304177), ('eat_VERB', -0.008918008615810973), ('animal_NOUN', 0.001362899732334417), ('vegetable_NOUN', 0.009861694036038437), ('anything_NOUN', 0.05928999338034457), ('cancer_NOUN', 0.09237859646593513), ('heart_NOUN', 0.16305741270042684), ('soil_NOUN', 0.24134317564299634), ('meat_NOUN', 0.279248632359523), ('attack_NOUN', 0.31830921074051177), ('corn_NOUN', 0.3828848091617086), ('food_NOUN', 0.39648253784764087), ('diet_NOUN', 0.47633619988239706), ('factory_NOUN', 0.4794943578349211), ('human_NOUN', 0.8140345403847936), ('die_VERB', 0.8573944338984882), ('face_NOUN', 0.9217015392500288), ('kill_VERB', 0.9519268716882943), ('life_NOUN', 0.981083412566036), ('grow_VERB', 0.9901176806652408), ('cow_NOUN', 0.9956592209474731)]\n",
      "\n",
      "\n",
      "against\n",
      "[('health_NOUN', -0.9703710480269583), ('soil_NOUN', -0.7586568243570037), ('study_NOUN', -0.7464849675276413), ('plant_NOUN', -0.6880487835816942), ('food_NOUN', -0.6035174621523591), ('diet_NOUN', -0.5236638001176029), ('human_NOUN', -0.1859654596152064), ('kill_VERB', -0.04807312831170572), ('grow_VERB', -0.009882319334759285), ('cow_NOUN', 0.004340779052526976), ('life_NOUN', 0.018916587433963978), ('face_NOUN', 0.07829846074997115), ('vegan_NOUN', 0.09506138033929604), ('fat_NOUN', 0.12237700659396973), ('die_VERB', 0.1426055661015117), ('vegetarian_NOUN', 0.2835305135413161), ('farming_NOUN', 0.286713114818573), ('farm_NOUN', 0.49630896353958154), ('factory_NOUN', 0.5205056421650789), ('corn_NOUN', 0.6171151908382915), ('attack_NOUN', 0.6816907892594882), ('meat_NOUN', 0.720751367640477), ('heart_NOUN', 0.8369425872995732), ('cancer_NOUN', 0.9076214035340648), ('anything_NOUN', 0.9407100066196554), ('vegetable_NOUN', 0.9901383059639616), ('eat_VERB', 0.9910819913841891), ('animal_NOUN', 0.9986371002676656)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('DS')\n",
    "side_idcs = {'for':0,'against':1}\n",
    "for side in sides:    \n",
    "    print(side)\n",
    "    sims = []\n",
    "    for clnum, (clmeasures, cl) in enumerate(zip(measures_all_debates_by_word[chosen_debate], all_data[chosen_debate])):    \n",
    "        if cl['type'] == \"word\" and 'DS_cos' in clmeasures[mask_type]:        \n",
    "            sims.append([cl['cluster_name'], clmeasures[mask_type]['DS_cos'][side]])\n",
    " \n",
    "    sims = sorted(sims, key=lambda k: k[1])\n",
    "\n",
    "    print([(w,s) for w,s  in sims if w in highest_tfidf_words[:200]])   \n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ad75fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS (grouping by type of behavior)\n",
      "common approaching:\n",
      "meat_NOUN 0.2792 0.7208 0.4415\n",
      "die_VERB 0.8574 0.1426 0.7148\n",
      "cancer_NOUN 0.0924 0.9076 0.8152\n",
      "heart_NOUN 0.1631 0.8369 0.6739\n",
      "life_NOUN 0.9811 0.0189 0.9622\n",
      "corn_NOUN 0.3829 0.6171 0.2342\n",
      "attack_NOUN 0.3183 0.6817 0.3634\n",
      "animal_NOUN 0.0014 0.9986 0.9973\n",
      "cow_NOUN 0.9957 0.0043 0.9913\n",
      "face_NOUN 0.9217 0.0783 0.8434\n",
      "vegetable_NOUN 0.0099 0.9901 0.9803\n",
      "anything_NOUN 0.0593 0.9407 0.8814\n",
      "factory_NOUN 0.4795 0.5205 0.041\n",
      "\n",
      "common distancing:\n",
      "health_NOUN -0.02962895197304177 -0.9703710480269583\n",
      "study_NOUN -0.25351503247235874 -0.7464849675276413\n",
      "plant_NOUN -0.31195121641830575 -0.6880487835816942\n",
      "\n",
      "opposite behavior:\n",
      "farm_NOUN -0.5037 0.4963 0.0074\n",
      "eat_VERB -0.0089 0.9911 0.9822\n",
      "grow_VERB 0.9901 -0.0099 0.9802\n",
      "food_NOUN 0.3965 -0.6035 0.207\n",
      "diet_NOUN 0.4763 -0.5237 0.0473\n",
      "fat_NOUN -0.8776 0.1224 0.7552\n",
      "vegetarian_NOUN -0.7165 0.2835 0.4329\n",
      "human_NOUN 0.814 -0.186 0.6281\n",
      "kill_VERB 0.9519 -0.0481 0.9039\n",
      "soil_NOUN 0.2413 -0.7587 0.5173\n",
      "vegan_NOUN -0.9049 0.0951 0.8099\n",
      "farming_NOUN -0.7133 0.2867 0.4266\n"
     ]
    }
   ],
   "source": [
    "print('DS (grouping by type of behavior)')\n",
    "side_idcs = {'for':0,'against':1}\n",
    "sims = dict()\n",
    "\n",
    "for clnum, (clmeasures, cl) in enumerate(zip(measures_all_debates_by_word[chosen_debate], all_data[chosen_debate])):    \n",
    "    sims_here = dict()\n",
    "    for side in sides:  \n",
    "        if cl['type'] == \"word\" and 'DS_cos' in clmeasures[mask_type]:        \n",
    "            sims_here[side] = clmeasures[mask_type]['DS_cos'][side]\n",
    "    if sims_here:    \n",
    "        if cl['cluster_name'] in highest_tfidf_words[:200]:\n",
    "            sims[cl[\"cluster_name\"]] = sims_here\n",
    "\n",
    "print(\"common approaching:\")\n",
    "for cl in sims:\n",
    "    if sims[cl]['for'] > 0 and sims[cl]['against'] > 0:\n",
    "        print(cl, sims[cl]['for'].round(4), sims[cl]['against'].round(4), abs(sims[cl]['for'] - sims[cl]['against']).round(4) )\n",
    "        \n",
    "print(\"\\ncommon distancing:\")\n",
    "for cl in sims:\n",
    "    if sims[cl]['for'] < 0 and sims[cl]['against'] < 0:\n",
    "        print(cl, sims[cl]['for'], sims[cl]['against'])\n",
    "\n",
    "        \n",
    "print(\"\\nopposite behavior:\")\n",
    "for cl in sims:\n",
    "    if (sims[cl]['for'] < 0 and sims[cl]['against'] > 0) or (sims[cl]['for'] > 0 and sims[cl]['against'] < 0):\n",
    "        print(cl, sims[cl]['for'].round(4), sims[cl]['against'].round(4), abs(abs(sims[cl]['for']) - abs(sims[cl]['against'])).round(4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb04a45",
   "metadata": {},
   "source": [
    "### SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af2c36a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1000, 'us // we')\n",
      "(-1000, 'a massive research study // The NIH-AARP study // it')\n",
      "(-1000, 'we')\n",
      "(0.0006321112515802781, 'vitamin B12 // B12')\n",
      "(0.0011061946902654867, \"the nation 's // the country\")\n",
      "(0.0029498525073746312, \"this motion // the motion 's // the motion\")\n",
      "(0.0029498525073746312, 'humans // human beings')\n",
      "(0.003982300884955752, 'animals // animals raised for meat')\n",
      "(0.004424778761061947, 'meat')\n",
      "(0.004424778761061947, 'cancer')\n",
      "(0.004424778761061947, 'vegetarians // the vegetarians')\n",
      "(0.004424778761061947, 'faces // a face')\n",
      "(0.004424778761061947, 'the globe // this world  s // the world')\n",
      "(0.004424778761061947, 'plants // Plants')\n",
      "(0.004424778761061947, 'corn // that corn')\n",
      "(0.004424778761061947, 'fish')\n"
     ]
    }
   ],
   "source": [
    "overlap_results = []\n",
    "freqs = []\n",
    "mask = \"no-mask\"\n",
    "clnums = []\n",
    "for clnum, cl in enumerate(measures_all_debates_by_word[chosen_debate]):\n",
    "    if 'SV' in cl[mask]: # mask type is irrelevant    \n",
    "        overlap_results.append(cl[mask]['SV']['value'])\n",
    "        freqs.append(cl[mask]['SV']['freq'])\n",
    "        clnums.append(clnum)\n",
    "\n",
    "\n",
    "        \n",
    "sum_freqs = sum([f for f in freqs if not np.isnan(f)])\n",
    "\n",
    "normalized_overlaps = [ov/sum_freqs if not np.isnan(ov) else np.nan for ov in overlap_results]\n",
    "\n",
    "normalized_overlaps_and_titles = list(zip(normalized_overlaps, [cluster_data[chosen_debate]['clusters'][clnum]['cluster_name'] for clnum in clnums])) #, range(len(normalized_overlaps))))\n",
    "\n",
    "# sorting a list with nans is problematic, we convert them to -1000 just so we can sort it\n",
    "sorted_normalized_overlaps_and_titles = sorted([(x[0], x[1]) if not np.isnan(x[0]) else (-1000, x[1]) for x in normalized_overlaps_and_titles], key= lambda k: k[0])\n",
    "\n",
    "\n",
    "for n in sorted_normalized_overlaps_and_titles:\n",
    "    print(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29773a1",
   "metadata": {},
   "source": [
    "With the code below we can check all mentions of a cluster by half and by speaker type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d6623ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALF\tSPEAKER TYPE\tMENTION\n",
      "first\tmod\t\tthat meat-eating is just nature 's way , and that meat in the diet makes a lot of sense .\n",
      "first\tmod\t\ttake the vegan or the vegetarian 's view that eating meat is just wrong for your health , for your\n",
      "first\tmod\t\teffects of diet on health . You do not eat meat now , but you come from a family of\n",
      "first\tfor\t\tof doubt you have as you 're getting away from meat are quickly replaced by being very , very glad\n",
      "first\tmod\t\t, whereas you are a guy who not only eats meat , but you also like to eat the bones\n",
      "first\tfor\t\tfor 10 years . Some of them did n't eat meat or did n't eat very much . Some ate\n",
      "first\tfor\t\teat very much . Some ate quite a lot of meat . And what they showed was that among those\n",
      "first\tfor\t\twhat they showed was that among those eating the most meat , the risk of dying of cancer was increased\n",
      "first\tfor\t\tthe same thing : if you ate a lot of meat , your risk of dying of heart disease was\n",
      "first\tfor\t\tstudies have clearly shown that people who do n't eat meat cut their cancer risk by anywhere between 12 and\n",
      "first\tfor\t\tatherosclerosis , they had narrowed arteries , he took the meat out of their diets , and something happened that\n",
      "first\tfor\t\tBecause when you get meat out of the diet , meat has fat in it and every gram of fat\n",
      "first\tfor\t\tand you get rid of a lot of calories . Meat has zero fiber , none . Fiber fills you\n",
      "first\tfor\t\tto gain weight . Why diabetes ? Because getting the meat out of the diet helps fat to drain out\n",
      "first\tfor\t\tthe heaviest group , and the people who eat no meat are always the thinnest . Diabetes is the same\n",
      "first\tfor\t\twhy more cancer ? Well , when we heat up meat , something happens that doesn  t happen with\n",
      "first\tfor\t\t s that carcinogens called heterocyclic amines form in the meat , especially chicken , but any kind of skeletal\n",
      "first\tfor\t\tbut any kind of skeletal muscle , which is what meat is . But that  s not the only\n",
      "first\tfor\t\tthe tobacco smoke is responsible . We know clearly that meat causes cancer in other parts of your body .\n",
      "first\tfor\t\tsaturated fat -- that  s the bad fat in meat -- is linked to Alzheimer  s disease in\n",
      "first\tagainst\t\tforum . And John , every time that I buy meat , I always think about the conditions the cow\n",
      "first\tagainst\t\tand dairy cows than it is for animals raised for meat . I  m sure that my opponent ,\n",
      "first\tagainst\t\t. Some groups emphasized dairy products , others emphasized organ meats and egg yolks , others the animal life of\n",
      "first\tagainst\t\t, synergizes with key amino acids found most abundantly in meat , bones , and skin . Is it possible\n",
      "first\tagainst\t\tto design an adequate diet that does not include the meat of animals with faces ? I actually think that\n",
      "first\tfor\t\tchoices and about the animals who suffer terribly for the meat , milk and eggs that is produced in this\n",
      "first\tmod\t\tFace . '' We heard them make the argument that meat raises the risk of getting sick ; that it\n",
      "first\tmod\t\tthey  re saying there is nothing as nutritious as meat , that it delivers nutrients in far greater density\n",
      "first\tmod\t\topened with the health argument , that food -- that meat -- makes you sick , that this is well-documented\n",
      "first\tmod\t\t. He felt terrible , and he went back to meat because his argument is that 's where the nutrients\n",
      "first\tagainst\t\tBarnard cited at the beginning about the relationship between eating meat and cancer and coronary heart disease are also observational\n",
      "first\tagainst\t\t, in Argentina , their per capita consumption of red meat is double what it is in the U.S .\n",
      "first\tagainst\t\taverage person eats half a pound a day of red meat , and their cancer rate is half of the\n",
      "first\tmod\t\targument that your opponents are making as well , that meat is just really damn nutritious and nothing can match\n",
      "first\tmod\t\t, you 're not going to get it without eating meat , unless you take supplements . Gene , do\n",
      "first\tfor\t\tabsorbing it . It 's hard to absorb B12 from meat . You need good stomach acid . You need\n",
      "first\tfor\t\tyears to develop . But studies also show that giving meat to those children does n't solve the problem .\n",
      "first\tfor\t\tYou can take a B12 deficient person , give them meat , and they will still be B12 deficient .\n",
      "first\tfor\t\t, every doctor always recommends , do n't rely on meat for B12 . They always recommend a supplement because\n",
      "first\tagainst\t\tevery weekend . She 's 90 . She 's eaten meat from day one , all of her life .\n",
      "first\tfor\t\ta randomized trial where you have half the people eat meat , and you track their cancer risk and have\n",
      "first\tfor\t\tissues about doing that because it is so clear that meat is linked to cancer , you could n't get\n",
      "first\tfor\t\tcigarettes . We know cigarettes cause cancer . We know meat is going to increase cancer risk . There are\n",
      "first\tagainst\t\twe could look at to improve our perspective on the meat and cancer relationship . One would be to try\n",
      "first\tagainst\t\tof populations that did not have modernized diets but had meat in their diets that were free of cancer .\n",
      "first\tagainst\t\t. We do n't know if they were protected by meat . But if you take a population of smokers\n",
      "first\tfor\t\t, look at hotdogs , bologna , all the processed meats , and colorectal cancer . And they concluded the\n",
      "first\tagainst\t\tYeah . But the problem is that all of your meat studies are based on toxin-laden meat that 's been\n",
      "first\tagainst\t\tthat all of your meat studies are based on toxin-laden meat that 's been raised in a factory-farming situation .\n",
      "second\tagainst\t\tthat if we do n't cook it and eat raw meat , then we 're okay and it 's okay\n",
      "second\tagainst\t\tthen we 're okay and it 's okay to eat meat with a face if we do n't cook it\n",
      "second\tfor\t\tThe point that I made is that when you analyze meat , some of the carcinogens are produced by cooking\n",
      "second\tfor\t\t, including cancers . And so that was not factory-farmed meat . It was range-fed meat or grazing animals ,\n",
      "second\tfor\t\tso that was not factory-farmed meat . It was range-fed meat or grazing animals , and they were still problems\n",
      "second\tagainst\t\tto the original data , there is no correlation between meat intake and cancer . If you read T. Colin\n",
      "second\tagainst\t\ta rather convoluted argument that some things are associated with meat , those things are associated with cancer , and\n",
      "second\tmod\t\tthe world is : you  ve got to eat meat , and there  s nothing wrong with that\n",
      "second\tfor\t\tdo to survive , and often that has been eating meat , but it  s also sometimes been eating\n",
      "second\tagainst\t\twhen they find out they can get healthy with our meat , but -- -- where I really get my\n",
      "second\tagainst\t\t's the topic . It 's not about eating less meat . I would even advocate eating less meat .\n",
      "second\tagainst\t\teating less meat . I would even advocate eating less meat . In fact , I think meat should be\n",
      "second\tagainst\t\tadvocate eating less meat . In fact , I think meat should be about three times more expensive than it\n",
      "second\tagainst\t\tand you can not be compassionate if you 're eating meat . That 's the motion . And it 's\n",
      "second\tfor\t\t, people would eat what seemed like a lot of meat , but they were still losing weight because they\n",
      "second\tfor\t\tare marginally slimmer than people who eat heavy amounts of meat , but they are nowhere near as slim as\n",
      "second\tagainst\t\tin that area -- eat 50 to 100 grams of meat per day . They hunt it and they use\n",
      "second\tunknown\t\tcome down to you . My name is Paul Strauss Meat is inexpensive , and I wonder what those in\n",
      "second\tfor\t\tsack of potatoes and work with that . And -- Meat is very expensive . You have to raise the\n",
      "second\tfor\t\the had a control group that was allowed to eat meat , leaner cuts and that kind of thing .\n",
      "second\tagainst\t\t. Same with -- That 's , of course , meat from a factory farm . No , no --\n",
      "second\tagainst\t\tthe same with -- The study was n't used pasture-based meat , was it ? Did it ? No ,\n",
      "second\tfor\t\toccurred with vegan diets . It never occurred with a meat diet . Okay . The answer to the woman\n",
      "second\tagainst\t\tstretching , and visualization , along with the exclusion of meat , reverses heart disease , perhaps , but has\n",
      "second\tagainst\t\tdisease , perhaps , but has n't shown that reversing meat , specifically , does . What this means is\n",
      "second\tfor\t\tsaid , `` I 'm not going to eat any meat , '' you 'd be thrilled , because you\n",
      "second\tfor\t\t, `` So I am living without fats , without meat , without fish . And I 'm feeling quite\n",
      "second\tagainst\t\tone of them was vegans . They both advocated eating meat . And if there certainly was an ethical dimension\n"
     ]
    }
   ],
   "source": [
    "word_of_interest = \"meat_NOUN\"\n",
    "\n",
    "doclen = len(cluster_data[chosen_debate]['document'])\n",
    "midpoint = doclen // 2\n",
    "\n",
    "print(\"HALF\\tSPEAKER TYPE\\tMENTION\")\n",
    "for clnum, cl in enumerate(cluster_data[chosen_debate]['clusters']):\n",
    "    if cl['cluster_name'] == word_of_interest:\n",
    "        for j, (ms, me) in enumerate(cl['mentions']):\n",
    "            if ms < midpoint:\n",
    "                h = 'first'\n",
    "            else:\n",
    "                h = 'second'\n",
    "            print(h + \"\\t\" + cl['speaker_types'][j] + \"\\t\\t\" + \" \".join(cluster_data[chosen_debate]['document'][ms-10:me+10]))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
