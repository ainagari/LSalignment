{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f03d6240",
   "metadata": {},
   "source": [
    "# Automatic Winner Prediction\n",
    "\n",
    "In this notebook, we:\n",
    "* load the alignment measures previously calculated and saved with the calculate_alignment.ipynb notebook,\n",
    "* Look at the values of these measures when either side wins and run tests of statistical significance,\n",
    "* Run the classification experiment (training and evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0355c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /home/aina/.convokit/downloads/iq2-corpus\n",
      "Dataset already exists at /home/aina/.convokit/downloads/iq2-corpus\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "import pickle\n",
    "from utils import obtain_winning_sides, load_cluster_info, load_iq2\n",
    "from scipy.stats import shapiro, mannwhitneyu, ttest_ind\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "ori_data = load_iq2()\n",
    "convid_to_title = dict(zip(ori_data['ConvID'], ori_data['ConvTitle']))\n",
    "\n",
    "\n",
    "winners, all_results = obtain_winning_sides()\n",
    "measures_all_debates = pickle.load(open(\"measures_all_debates.pkl\", \"rb\"))\n",
    "cluster_data = load_cluster_info(\"debates_full_chains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c94b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def select_features(measures_all_debates, setting, data_split, all_debate_results):\n",
    "    \n",
    "    sides = ['for','against']\n",
    "    \n",
    "    ours_symmetric = [\"TUOS_cos\", \"TUOS_eucl\", 'sApp_cos', 'sApp_eucl', 'SV']\n",
    "    ours_asymmetric = [\"TUSS_cos\",\"TUSS_eucl\", 'TASS_cos', 'TASS_eucl', 'DS_cos','DS_eucl','asApp_cos','asApp_eucl']\n",
    "    dialign_symmetric = ['Expression Repetition', 'Voc. Overlap', 'Num. utterances', 'Num. tokens', 'Expression Lexicon Size (ELS)', 'Expression Variety (EV)', 'Expression Repetition (ER)', 'ENTR', 'L', 'LMAX']\n",
    "    dialign_asymmetric = ['Initiated Expression', 'tokens (%)', 'SR/Voc. Overlap', 'SR/ELS', 'SR/EV', 'SR/ER', 'SR/ENTR', 'SR/L', 'SR/LMAX']\n",
    "    \n",
    "    if setting['measures_to_include'] == \"ours\":\n",
    "        measures_to_include = ours_asymmetric + ours_symmetric\n",
    "    elif setting['measures_to_include'] == \"ours_asym\":\n",
    "        measures_to_include = ours_asymmetric\n",
    "    elif setting['measures_to_include'] == \"dialign_asym\":\n",
    "        measures_to_include = dialign_asymmetric\n",
    "    elif setting['measures_to_include'] == \"ours_asym+dialign_asym\":\n",
    "        measures_to_include = ours_asymmetric + dialign_asymmetric\n",
    "    elif setting['measures_to_include'] == \"baseline_tokens\":\n",
    "        measures_to_include = ['tokens (%)', 'Num. tokens', 'Num. utterances']    \n",
    "    \n",
    "    similarity_based_measure_names = [m for m in ours_symmetric+ours_asymmetric if \"_cos\" in m or \"_eucl\" in m]    \n",
    "        \n",
    "    list_of_feature_names = []    \n",
    "   \n",
    "    X = dict()\n",
    "    y = dict()\n",
    "    for subset in data_split:\n",
    "        X[subset] = []\n",
    "        y[subset] = []\n",
    "        for i, debate_id in enumerate(data_split[subset]):\n",
    "            v = []       \n",
    "            # pick the relevant features, build the feature vector, and append it to X[subset]\n",
    "            info_this_debate = measures_all_debates[debate_id][setting['vocabulary']][setting['mask']]\n",
    "            for measure in info_this_debate:                               \n",
    "                if measure in measures_to_include:                    \n",
    "                    if measure in similarity_based_measure_names and setting['similarity'] not in measure:\n",
    "                        continue                                                            \n",
    "                    if measure in ours_symmetric+dialign_symmetric: # if measure is symmetric                    \n",
    "                        v.append(info_this_debate[measure])\n",
    "                        if i == 0 and subset == \"train\": # only do this once in the loop\n",
    "                            list_of_feature_names.append(setting['vocabulary'] + \"%\" + measure)\n",
    "                    else:   # if measure is asymmetric\n",
    "                        for side in sides:\n",
    "                            v.append(info_this_debate[measure][side])\n",
    "                            if i == 0 and subset == \"train\":\n",
    "                                list_of_feature_names.append(setting['vocabulary'] + \"%\" + measure + \"-\" + side)                        \n",
    "\n",
    "            X[subset].append(v)                   \n",
    "            \n",
    "            yval = sides.index(all_debate_results[debate_id]['winner']) # 0 for for, 1 for against                                \n",
    "            y[subset].append(yval)\n",
    "            \n",
    "        X[subset] = np.array(X[subset])\n",
    "        y[subset] = np.array(y[subset])          \n",
    "        \n",
    "    return X, y, list_of_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4eea08",
   "metadata": {},
   "source": [
    "### Measure values when different sides win the debate + significance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0e5d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASS_cos%against \tp = 0.017 \td = -0.476\n",
      "TASS_cos%for \tp = 0.037 \td = -0.412\n",
      "TASS_eucl%against \tp = 0.046 \td = 0.394\n",
      "TUSS_cos%against \tp = 0.063 \td = -0.367\n",
      "TASS_eucl%for \tp = 0.084 \td = 0.341\n",
      "SR/Voc. Overlap%for \tp = 0.096 \td = -0.328\n",
      "SR/EV%for \tp = 0.19 \td = -0.254\n",
      "TUSS_cos%for \tp = 0.223 \td = -0.239\n",
      "SR/LMAX%against \tp = 0.228 \td = 0.294\n",
      "TUSS_eucl%against \tp = 0.236 \td = 0.233\n",
      "SR/EV%against \tp = 0.272 \td = -0.257\n",
      "Initiated Expression%for \tp = 0.313 \td = 0.198\n",
      "Initiated Expression%against \tp = 0.313 \td = -0.198\n",
      "DS_eucl%for \tp = 0.32 \td = -0.195\n",
      "SR/ENTR%against \tp = 0.358 \td = 0.123\n",
      "SR/L%against \tp = 0.385 \td = 0.316\n",
      "Expression Repetition%against \tp = 0.404 \td = 0.164\n",
      "TUSS_eucl%for \tp = 0.406 \td = 0.163\n",
      "SR/ELS%for \tp = 0.469 \td = 0.142\n",
      "DS_eucl%against \tp = 0.477 \td = -0.139\n",
      "tokens (%)%against \tp = 0.509 \td = -0.129\n",
      "tokens (%)%for \tp = 0.509 \td = 0.129\n",
      "asApp_eucl%against \tp = 0.523 \td = -0.125\n",
      "DS_cos%against \tp = 0.542 \td = -0.119\n",
      "SR/ELS%against \tp = 0.558 \td = 0.03\n",
      "SR/ENTR%for \tp = 0.569 \td = -0.111\n",
      "asApp_cos%against \tp = 0.571 \td = -0.111\n",
      "asApp_eucl%for \tp = 0.59 \td = -0.106\n",
      "SR/LMAX%for \tp = 0.61 \td = -0.034\n",
      "DS_cos%for \tp = 0.616 \td = -0.098\n",
      "Expression Repetition%for \tp = 0.689 \td = -0.105\n",
      "SR/Voc. Overlap%against \tp = 0.799 \td = -0.05\n",
      "SR/ER%for \tp = 0.835 \td = -0.041\n",
      "SR/L%for \tp = 0.865 \td = 0.141\n",
      "asApp_cos%for \tp = 0.875 \td = -0.031\n",
      "SR/ER%against \tp = 0.984 \td = 0.004\n"
     ]
    }
   ],
   "source": [
    "def cohen_d(x,y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof)\n",
    "\n",
    "mask_type = \"no-mask\"\n",
    "vocab_option = \"tfidf200\"\n",
    "xs = defaultdict(list)\n",
    "\n",
    "all_debate_ids = [di for di in all_results if all_results[di]['winner'] != \"tie\"]\n",
    "wnss = [all_results[debate_id]['winner'] for debate_id in all_debate_ids]\n",
    "\n",
    "   \n",
    "for debate_id in all_debate_ids:        \n",
    "    for measure in measures_all_debates[debate_id][vocab_option][mask_type]:\n",
    "        if type(measures_all_debates[debate_id][vocab_option][mask_type][measure]) == type(dict()): # asymmetric measures            \n",
    "            for side in measures_all_debates[debate_id][vocab_option][mask_type][measure]:\n",
    "                measurename = measure + \"%\" + side \n",
    "                xs[measurename].append(measures_all_debates[debate_id][vocab_option][mask_type][measure][side])            \n",
    "\n",
    "# Run statistical tests\n",
    "# Ttest if normality, Mann whitney U otherwise\n",
    "winners_measures_significance = []\n",
    "for measurename in xs:    \n",
    "    assert len(wnss) == len(xs[measurename])\n",
    "    for_values = [x for x, w in zip(xs[measurename], wnss) if w == \"for\"] # values in debates where FOR won\n",
    "    against_values = [x for x, w in zip(xs[measurename], wnss) if w == \"against\"] # values in debates where AGAINST won\n",
    "    \n",
    "    if shapiro(for_values)[1] > 0.05 and shapiro(against_values)[1] > 0.05:\n",
    "        pval = ttest_ind(for_values, against_values)[1]    \n",
    "    else:\n",
    "        pval = mannwhitneyu(for_values, against_values)[1]\n",
    "        \n",
    "    d = cohen_d(for_values, against_values) # effect size\n",
    "        \n",
    "    winners_measures_significance.append((measurename, pval, d))\n",
    "    \n",
    "sorted_winners_measures_significance = sorted(winners_measures_significance, key=lambda i: i[-2])\n",
    "for m, p, d in sorted_winners_measures_significance:    \n",
    "    print(m, \"\\tp =\", p.round(3), \"\\td =\", d.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578dc5f",
   "metadata": {},
   "source": [
    "# Leave-one-out setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb36eb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up leave-one-out splits\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "all_debate_ids = [x for x in cluster_data if winners[x] != \"tie\"]\n",
    "loo.get_n_splits(all_debate_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "380c8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare every setting we want to test\n",
    "\n",
    "mask_type = \"no-mask\"\n",
    "\n",
    "# possible measure combinations\n",
    "# ours: symmetric + asymmetric\n",
    "# ours_asym: ours only asymmetric\n",
    "# dialign_asym: dialign only asymmetric\n",
    "# ours_asym+dialign_asym: ours only asymmetric + dialign only asymmetric\n",
    "# baseline_tokens: num tokens, num utterances, tokens (%)\n",
    "\n",
    "\n",
    "all_settings = []\n",
    "all_settings.append({'mask':mask_type,'vocabulary':'all','similarity':'', 'measures_to_include':'dialign_asym'})\n",
    "all_settings.append({'mask':mask_type,'vocabulary':'all','similarity':'', 'measures_to_include':'baseline_tokens'})\n",
    "for distance in [\"cos\",\"eucl\"]:\n",
    "    for vocab in [\"all\",\"tfidf200\", \"tfidf200_C\"]:         \n",
    "        all_settings.append({'mask':mask_type,'vocabulary':vocab,'similarity':distance, 'measures_to_include':'ours'})\n",
    "        all_settings.append({'mask':mask_type,'vocabulary':vocab,'similarity':distance, 'measures_to_include':'ours_asym'})\n",
    "        all_settings.append({'mask':mask_type,'vocabulary':vocab,'similarity':distance, 'measures_to_include':'ours_asym+dialign_asym'})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef3c02",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e1a26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sides = ['for','against']\n",
    "\n",
    "for setting in all_settings:\n",
    "    setting['predictions_classification'] = []   \n",
    "    \n",
    "\n",
    "truths_classif = []\n",
    "for loo_n, (train_idcs, test_idcs) in enumerate(loo.split(all_debate_ids)):    \n",
    "    train_ids = [all_debate_ids[i] for i in train_idcs]\n",
    "    test_ids = [all_debate_ids[i] for i in test_idcs]    \n",
    "    truths_classif.append(sides.index(all_results[test_ids[0]]['winner']))    \n",
    "    for setting in all_settings:                \n",
    "        splitting = {'train':train_ids,\"test\":test_ids}\n",
    "        X, y, list_of_feature_names = select_features(measures_all_debates, setting, splitting, all_results)               \n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X['train'] = scaler.fit_transform(X['train']) \n",
    "        X['test'] = scaler.transform(X['test'])\n",
    "        \n",
    "        logreg = LogisticRegression(solver='liblinear')        \n",
    "        logreg.fit(X['train'],y['train'])        \n",
    "        prediction = logreg.predict(X['test'])[0]\n",
    "        setting['predictions_classification'].append(prediction)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119f55aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEASURES\tSIM/DIST\tVOCAB\tACC\n",
      "ours_asym\tcos\tall\t0.57\n",
      "ours_asym\tcos\ttfidf200_C\t0.57\n",
      "ours\teucl\ttfidf200\t0.57\n",
      "ours_asym\teucl\ttfidf200\t0.57\n",
      "ours_asym\teucl\ttfidf200_C\t0.57\n",
      "ours\tcos\ttfidf200\t0.55\n",
      "ours_asym\tcos\ttfidf200\t0.54\n",
      "ours_asym+dialign_asym\tcos\ttfidf200_C\t0.54\n",
      "ours\teucl\ttfidf200_C\t0.54\n",
      "ours_asym+dialign_asym\teucl\ttfidf200_C\t0.54\n",
      "dialign_asym\t\tall\t0.52\n",
      "ours_asym+dialign_asym\tcos\tall\t0.52\n",
      "ours_asym\teucl\tall\t0.52\n",
      "ours_asym+dialign_asym\teucl\tall\t0.52\n",
      "ours_asym+dialign_asym\teucl\ttfidf200\t0.51\n",
      "ours\tcos\ttfidf200_C\t0.5\n",
      "majority baseline\t\t\t0.5\n",
      "ours_asym+dialign_asym\tcos\ttfidf200\t0.5\n",
      "baseline_tokens\t\tall\t0.49\n",
      "ours\tcos\tall\t0.49\n",
      "ours\teucl\tall\t0.47\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate all settings\n",
    "for setting in all_settings:\n",
    "    setting['accuracy'] = accuracy_score(truths_classif, setting['predictions_classification'])\n",
    "    \n",
    "settings_results = dict()\n",
    "for setting in all_settings:\n",
    "    newsetting = {d:setting[d] for d in setting.keys() if 'predictions' not in d and \"result\" not in d}\n",
    "    settings_results[tuple(newsetting.items())] = setting['accuracy']\n",
    "\n",
    "    \n",
    "majoritybaseline_setting = {'similarity':'','vocabulary':'', 'measures_to_include': 'majority baseline', 'accuracy': accuracy_score(truths_classif, [1]*len(truths_classif))}\n",
    "\n",
    "   \n",
    "sorted_results = sorted(all_settings + [majoritybaseline_setting], key= lambda i: i['accuracy'], reverse=True)\n",
    "\n",
    "\n",
    "print(\"MEASURES\\tSIM/DIST\\tVOCAB\\tACC\")\n",
    "for setting in sorted_results:\n",
    "    print(setting['measures_to_include'] + \"\\t\" + setting['similarity'] + \"\\t\" + setting['vocabulary'] + \"\\t\" + str(setting['accuracy'].round(2)))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
